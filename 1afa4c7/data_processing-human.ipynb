{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13b66fbe",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [18]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "papermill": {
     "duration": 0.005634,
     "end_time": "2024-10-27T14:53:57.883309",
     "exception": false,
     "start_time": "2024-10-27T14:53:57.877675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:53:57.895718Z",
     "iopub.status.busy": "2024-10-27T14:53:57.895155Z",
     "iopub.status.idle": "2024-10-27T14:53:59.100487Z",
     "shell.execute_reply": "2024-10-27T14:53:59.099850Z"
    },
    "papermill": {
     "duration": 1.213827,
     "end_time": "2024-10-27T14:53:59.102109",
     "exception": false,
     "start_time": "2024-10-27T14:53:57.888282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from scipy.stats import iqr\n",
    "import shutil\n",
    "import zipfile\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:53:59.113401Z",
     "iopub.status.busy": "2024-10-27T14:53:59.113075Z",
     "iopub.status.idle": "2024-10-27T14:53:59.116330Z",
     "shell.execute_reply": "2024-10-27T14:53:59.115781Z"
    },
    "papermill": {
     "duration": 0.010378,
     "end_time": "2024-10-27T14:53:59.117714",
     "exception": false,
     "start_time": "2024-10-27T14:53:59.107336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:53:59.128756Z",
     "iopub.status.busy": "2024-10-27T14:53:59.128304Z",
     "iopub.status.idle": "2024-10-27T14:54:00.028679Z",
     "shell.execute_reply": "2024-10-27T14:54:00.027916Z"
    },
    "papermill": {
     "duration": 0.90764,
     "end_time": "2024-10-27T14:54:00.030312",
     "exception": false,
     "start_time": "2024-10-27T14:53:59.122672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "ğŸ‘‹ Hello! This is openneuro-py 2024.2.0. Great to see you! ğŸ¤—\r\n",
      "\r\n",
      "   ğŸ‘‰ Please report problems ğŸ¤¯ and bugs ğŸª² at\r\n",
      "      https://github.com/hoechenberger/openneuro-py/issues\r\n",
      "\r\n",
      "ğŸŒ Preparing to download ds005025 â€¦\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphQL query failed with 1 errors\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/openneu\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33mro/\u001b[0m\u001b[1;33m_download.py\u001b[0m:\u001b[94m217\u001b[0m in \u001b[92m_get_download_metadata\u001b[0m                                \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m msg == \u001b[33m\"\u001b[0m\u001b[33mYou do not have access to read this dataset.\u001b[0m\u001b[33m\"\u001b[0m:  \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m215 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mtry\u001b[0m:                                                   \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m216 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[2m# Do we have an API token?\u001b[0m                         \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m217 \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0mget_token()                                        \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m218 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(                                \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m219 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mWe were not permitted to download \u001b[0m\u001b[33m\"\u001b[0m           \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m220 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mthis dataset. Perhaps your user \u001b[0m\u001b[33m\"\u001b[0m             \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ•­â”€\u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33m locals \u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33mâ”€â•®\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m          base_url = \u001b[33m'https://openneuro.org/'\u001b[0m                             \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m    check_snapshot = \u001b[94mTrue\u001b[0m                                                 \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m        dataset_id = \u001b[33m'ds005025'\u001b[0m                                           \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m       max_retries = \u001b[94m5\u001b[0m                                                    \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m               msg = \u001b[33m'You do not have access to read this dataset.'\u001b[0m       \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m             query = \u001b[33m'\\n    query \u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m\\n        dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mid: \"ds005025\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m\\n \u001b[0m \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[33mlatestSnapshot \u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m\\n    '\u001b[0m+\u001b[94m219\u001b[0m                          \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m request_timed_out = \u001b[94mFalse\u001b[0m                                                \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m     response_json = \u001b[1m{\u001b[0m                                                    \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   \u001b[0m\u001b[33m'errors'\u001b[0m: \u001b[1m[\u001b[0m                                      \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[1m{\u001b[0m                                            \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33m'message'\u001b[0m: \u001b[33m'You do not have access to \u001b[0m   \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[33mread this dataset.'\u001b[0m,                                 \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33m'locations'\u001b[0m: \u001b[1m[\u001b[0m                           \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[1m{\u001b[0m\u001b[33m'line'\u001b[0m: \u001b[94m3\u001b[0m, \u001b[33m'column'\u001b[0m: \u001b[94m9\u001b[0m\u001b[1m}\u001b[0m             \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[1m]\u001b[0m,                                       \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33m'path'\u001b[0m: \u001b[1m[\u001b[0m\u001b[33m'dataset'\u001b[0m\u001b[1m]\u001b[0m,                     \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33m'extensions'\u001b[0m: \u001b[1m{\u001b[0m                          \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m'code'\u001b[0m: \u001b[33m'INTERNAL_SERVER_ERROR'\u001b[0m,     \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m'stacktrace'\u001b[0m: \u001b[1m[\u001b[0m                      \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m'Error: You do not have access \u001b[0m  \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[33mto read this dataset.'\u001b[0m,                              \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m'    at checkDatasetRead \u001b[0m        \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[33m/srv/packages/openneuro-server/dist/graphql/permisâ€¦\u001b[0m \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m'    at \u001b[0m                         \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[33mprocess.processTicksAndRejections \u001b[0m                   \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[33mnode:internal/process/task_queues:95:5'\u001b[0m+\u001b[94m1\u001b[0m,          \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m'    at async dataset \u001b[0m           \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[33m/srv/packages/openneuro-server/dist/graphql/resolvâ€¦\u001b[0m \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[1m]\u001b[0m                                    \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[1m}\u001b[0m                                        \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[1m}\u001b[0m                                            \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   \u001b[0m\u001b[1m]\u001b[0m,                                               \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   \u001b[0m\u001b[33m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[33m'dataset'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m,                       \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   \u001b[0m\u001b[33m'extensions'\u001b[0m: \u001b[1m{\u001b[0m                                  \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[33m'openneuro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[33m'version'\u001b[0m: \u001b[33m'4.28.3'\u001b[0m\u001b[1m}\u001b[0m           \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   \u001b[0m\u001b[1m}\u001b[0m                                                \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[1m}\u001b[0m                                                    \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m     retry_backoff = \u001b[94m0.5\u001b[0m                                                  \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m               tag = \u001b[94mNone\u001b[0m                                                 \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m              tree = \u001b[33m'null'\u001b[0m                                               \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/openneu\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33mro/\u001b[0m\u001b[1;33m_config.py\u001b[0m:\u001b[94m72\u001b[0m in \u001b[92mget_token\u001b[0m                                                \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m69 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                    \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m70 \u001b[0m\u001b[2;33mâ”‚   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m71 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m CONFIG_PATH.exists():                                        \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m72 \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                               \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m73 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCould not read API token as no openneuro-py configuration \u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m74 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33m'\u001b[0m\u001b[33mfile exists. Run \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mopenneuro login\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m to generate it.\u001b[0m\u001b[33m'\u001b[0m        \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m75 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m)                                                               \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\r\n",
      "\u001b[1;91mValueError: \u001b[0mCould not read API token as no openneuro-py configuration file \r\n",
      "exists. Run \u001b[32m\"openneuro login\"\u001b[0m to generate it.\r\n",
      "\r\n",
      "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\r\n",
      "\r\n",
      "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/openneu\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33mro/\u001b[0m\u001b[1;33m_cli.py\u001b[0m:\u001b[94m64\u001b[0m in \u001b[92mdownload_cli\u001b[0m                                                \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2mâ”‚   \u001b[0m] = \u001b[94m5\u001b[0m,                                                             \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 62 \u001b[0m) -> \u001b[94mNone\u001b[0m:                                                             \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 63 \u001b[0m\u001b[2;90mâ”‚   \u001b[0m\u001b[33m\"\"\"Download datasets from OpenNeuro.\"\"\"\u001b[0m                            \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m 64 \u001b[2mâ”‚   \u001b[0mdownload(                                                          \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mdataset=dataset,                                               \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 66 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mtag=tag,                                                       \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m 67 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mtarget_dir=target_dir,                                         \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ•­â”€\u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33m locals \u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33mâ”€â•®\u001b[0m                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                  dataset = \u001b[33m'ds005025'\u001b[0m    \u001b[33mâ”‚\u001b[0m                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                  exclude = \u001b[94mNone\u001b[0m          \u001b[33mâ”‚\u001b[0m                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                  include = \u001b[94mNone\u001b[0m          \u001b[33mâ”‚\u001b[0m                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m max_concurrent_downloads = \u001b[94m5\u001b[0m             \u001b[33mâ”‚\u001b[0m                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m              max_retries = \u001b[94m5\u001b[0m             \u001b[33mâ”‚\u001b[0m                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                      tag = \u001b[94mNone\u001b[0m          \u001b[33mâ”‚\u001b[0m                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m               target_dir = \u001b[33m'data-human/'\u001b[0m \u001b[33mâ”‚\u001b[0m                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m              verify_hash = \u001b[94mTrue\u001b[0m          \u001b[33mâ”‚\u001b[0m                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m              verify_size = \u001b[94mTrue\u001b[0m          \u001b[33mâ”‚\u001b[0m                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/openneu\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33mro/\u001b[0m\u001b[1;33m_download.py\u001b[0m:\u001b[94m791\u001b[0m in \u001b[92mdownload\u001b[0m                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2mâ”‚   \u001b[0mexclude = [] \u001b[94mif\u001b[0m exclude \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mlist\u001b[0m(exclude)                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m789 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                   \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m790 \u001b[0m\u001b[2mâ”‚   \u001b[0mretry_backoff = \u001b[94m0.5\u001b[0m  \u001b[2m# seconds\u001b[0m                                     \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m791 \u001b[2mâ”‚   \u001b[0mmetadata = _get_download_metadata(                                 \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m792 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mdataset_id=dataset,                                            \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m793 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mtag=tag,                                                       \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m794 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mmax_retries=max_retries,                                       \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ•­â”€\u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33m locals \u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33mâ”€â•®\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                  dataset = \u001b[33m'ds005025'\u001b[0m                                    \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                  exclude = \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m                                            \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                  include = \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m                                            \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m max_concurrent_downloads = \u001b[94m5\u001b[0m                                             \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m              max_retries = \u001b[94m5\u001b[0m                                             \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                      msg = \u001b[33m'\\nğŸ‘‹ Hello! This is openneuro-py 2024.2.0. \u001b[0m  \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                            \u001b[33mGreat to see you! ğŸ¤—\\n\\n   ğŸ‘‰ Please \u001b[0m         \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                            \u001b[33mreport'\u001b[0m+\u001b[94m85\u001b[0m                                    \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                 msg_bugs = \u001b[33m'bugs ğŸª²'\u001b[0m                                     \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m     msg_great_to_see_you = \u001b[33m'Great to see you! ğŸ¤—'\u001b[0m                        \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                msg_hello = \u001b[33m'ğŸ‘‹ Hello!'\u001b[0m                                   \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m               msg_please = \u001b[33m'ğŸ‘‰ Please'\u001b[0m                                   \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m             msg_problems = \u001b[33m'problems ğŸ¤¯'\u001b[0m                                 \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m            retry_backoff = \u001b[94m0.5\u001b[0m                                           \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                      tag = \u001b[94mNone\u001b[0m                                          \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m               target_dir = \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[33m'/home/runner/work/coil-qc-code/coâ€¦\u001b[0m \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m              verify_hash = \u001b[94mTrue\u001b[0m                                          \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m              verify_size = \u001b[94mTrue\u001b[0m                                          \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/openneu\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[2;33mro/\u001b[0m\u001b[1;33m_download.py\u001b[0m:\u001b[94m226\u001b[0m in \u001b[92m_get_download_metadata\u001b[0m                                \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m223 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m)                                                  \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m224 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mValueError\u001b[0m \u001b[94mas\u001b[0m e:                                \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m225 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[2m# We don't have an API token.\u001b[0m                      \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m226 \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(                                \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mIt seems that this is a restricted \u001b[0m\u001b[33m\"\u001b[0m          \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m228 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mdataset. However, your API token is \u001b[0m\u001b[33m\"\u001b[0m         \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m   \u001b[2m229 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mnot configured properly, so we could \u001b[0m\u001b[33m\"\u001b[0m        \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m                                                                              \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ•­â”€\u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33m locals \u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33mâ”€â•®\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m          base_url = \u001b[33m'https://openneuro.org/'\u001b[0m                             \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m    check_snapshot = \u001b[94mTrue\u001b[0m                                                 \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m        dataset_id = \u001b[33m'ds005025'\u001b[0m                                           \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m       max_retries = \u001b[94m5\u001b[0m                                                    \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m               msg = \u001b[33m'You do not have access to read this dataset.'\u001b[0m       \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m             query = \u001b[33m'\\n    query \u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m\\n        dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mid: \"ds005025\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m\\n \u001b[0m \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[33mlatestSnapshot \u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m\\n    '\u001b[0m+\u001b[94m219\u001b[0m                          \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m request_timed_out = \u001b[94mFalse\u001b[0m                                                \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m     response_json = \u001b[1m{\u001b[0m                                                    \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   \u001b[0m\u001b[33m'errors'\u001b[0m: \u001b[1m[\u001b[0m                                      \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[1m{\u001b[0m                                            \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33m'message'\u001b[0m: \u001b[33m'You do not have access to \u001b[0m   \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[33mread this dataset.'\u001b[0m,                                 \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33m'locations'\u001b[0m: \u001b[1m[\u001b[0m                           \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[1m{\u001b[0m\u001b[33m'line'\u001b[0m: \u001b[94m3\u001b[0m, \u001b[33m'column'\u001b[0m: \u001b[94m9\u001b[0m\u001b[1m}\u001b[0m             \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[1m]\u001b[0m,                                       \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33m'path'\u001b[0m: \u001b[1m[\u001b[0m\u001b[33m'dataset'\u001b[0m\u001b[1m]\u001b[0m,                     \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33m'extensions'\u001b[0m: \u001b[1m{\u001b[0m                          \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m'code'\u001b[0m: \u001b[33m'INTERNAL_SERVER_ERROR'\u001b[0m,     \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m'stacktrace'\u001b[0m: \u001b[1m[\u001b[0m                      \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m'Error: You do not have access \u001b[0m  \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[33mto read this dataset.'\u001b[0m,                              \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m'    at checkDatasetRead \u001b[0m        \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[33m/srv/packages/openneuro-server/dist/graphql/permisâ€¦\u001b[0m \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m'    at \u001b[0m                         \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[33mprocess.processTicksAndRejections \u001b[0m                   \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[33mnode:internal/process/task_queues:95:5'\u001b[0m+\u001b[94m1\u001b[0m,          \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[33m'    at async dataset \u001b[0m           \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[33m/srv/packages/openneuro-server/dist/graphql/resolvâ€¦\u001b[0m \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[1m]\u001b[0m                                    \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[1m}\u001b[0m                                        \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[1m}\u001b[0m                                            \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   \u001b[0m\u001b[1m]\u001b[0m,                                               \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   \u001b[0m\u001b[33m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[33m'dataset'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m,                       \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   \u001b[0m\u001b[33m'extensions'\u001b[0m: \u001b[1m{\u001b[0m                                  \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[33m'openneuro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[33m'version'\u001b[0m: \u001b[33m'4.28.3'\u001b[0m\u001b[1m}\u001b[0m           \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[2mâ”‚   \u001b[0m\u001b[1m}\u001b[0m                                                \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m                     \u001b[1m}\u001b[0m                                                    \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m     retry_backoff = \u001b[94m0.5\u001b[0m                                                  \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m               tag = \u001b[94mNone\u001b[0m                                                 \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ”‚\u001b[0m              tree = \u001b[33m'null'\u001b[0m                                               \u001b[33mâ”‚\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ”‚\u001b[0m \u001b[33mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m \u001b[31mâ”‚\u001b[0m\r\n",
      "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\r\n",
      "\u001b[1;91mRuntimeError: \u001b[0mIt seems that this is a restricted dataset. However, your API \r\n",
      "token is not configured properly, so we could not log you in. Could not read API\r\n",
      "token as no openneuro-py configuration file exists. Run \u001b[32m\"openneuro login\"\u001b[0m to \r\n",
      "generate it.\r\n"
     ]
    }
   ],
   "source": [
    "# Download data from OpenNeuro â³\n",
    "\n",
    "!openneuro-py download --dataset ds005025 --target-dir data-human/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.043130Z",
     "iopub.status.busy": "2024-10-27T14:54:00.042669Z",
     "iopub.status.idle": "2024-10-27T14:54:00.048587Z",
     "shell.execute_reply": "2024-10-27T14:54:00.047951Z"
    },
    "papermill": {
     "duration": 0.013769,
     "end_time": "2024-10-27T14:54:00.049940",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.036171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_data: /home/runner/work/coil-qc-code/coil-qc-code/data-human/\n",
      "subjects: []\n"
     ]
    }
   ],
   "source": [
    "# Define useful variables\n",
    "path_data = os.path.join(os.getcwd(), \"data-human/\")\n",
    "print(f\"path_data: {path_data}\")\n",
    "path_labels = os.path.join(path_data, \"derivatives\", \"labels\")\n",
    "path_qc = os.path.join(path_data, \"qc\")\n",
    "subjects = [os.path.basename(subject_path) for subject_path in sorted(glob.glob(os.path.join(path_data, \"sub-*\")))]\n",
    "print(f\"subjects: {subjects}\")\n",
    "\n",
    "# Create output folder\n",
    "path_results = os.path.join(path_data, \"derivatives\", \"results\")\n",
    "os.makedirs(path_results, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "papermill": {
     "duration": 0.005532,
     "end_time": "2024-10-27T14:54:00.061074",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.055542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MP2RAGE segmentation and vertebral labeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.073491Z",
     "iopub.status.busy": "2024-10-27T14:54:00.073047Z",
     "iopub.status.idle": "2024-10-27T14:54:00.079081Z",
     "shell.execute_reply": "2024-10-27T14:54:00.078506Z"
    },
    "papermill": {
     "duration": 0.013878,
     "end_time": "2024-10-27T14:54:00.080409",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.066531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run segmentation on MP2RAGE scan â³\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"anat\"))\n",
    "    fname_manual_seg = os.path.join(path_labels, subject, \"anat\", f\"{subject}_UNIT1_label-SC_seg.nii.gz\")\n",
    "    if os.path.exists(fname_manual_seg):\n",
    "        # Manual segmentation already exists. Copy it to local folder\n",
    "        print(f\"{subject}: Manual segmentation found\\n\")\n",
    "        shutil.copyfile(fname_manual_seg, f\"{subject}_UNIT1_seg.nii.gz\")\n",
    "        # Generate QC report to make sure the manual segmentation is correct\n",
    "        !sct_qc -i {subject}_UNIT1.nii.gz -s {subject}_UNIT1_seg.nii.gz -p sct_deepseg_sc -qc {path_qc} -qc-subject {subject}\n",
    "    else:\n",
    "        # Manual segmentation does not exist. Run automatic segmentation.\n",
    "        print(f\"{subject}: Manual segmentation not found\")\n",
    "        #EAO: remove -qc {path_qc} because its giving me an error\n",
    "        !sct_deepseg -i \"{subject}_UNIT1.nii.gz\" -task seg_sc_contrast_agnostic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.092756Z",
     "iopub.status.busy": "2024-10-27T14:54:00.092300Z",
     "iopub.status.idle": "2024-10-27T14:54:00.098189Z",
     "shell.execute_reply": "2024-10-27T14:54:00.097650Z"
    },
    "papermill": {
     "duration": 0.01347,
     "end_time": "2024-10-27T14:54:00.099497",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.086027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Label vertebrae\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"anat\"))\n",
    "    fname_manual_labels = os.path.join(path_labels, subject, \"anat\", f\"{subject}_UNIT1_label-disc.nii.gz\")\n",
    "    if os.path.exists(fname_manual_labels):\n",
    "        # Use manual disc labels to generate labeled segmentation.\n",
    "        print(f\"{subject}: Manual labels found\\n\")\n",
    "        !sct_label_utils -i {subject}_UNIT1_seg.nii.gz -disc {fname_manual_labels} -o {subject}_UNIT1_seg_labeled.nii.gz\n",
    "        # Generate QC report to assess labeled segmentation\n",
    "        !sct_qc -i {subject}_UNIT1.nii.gz -s {subject}_UNIT1_seg_labeled.nii.gz -p sct_label_vertebrae -qc {path_qc} -qc-subject {subject}\n",
    "    else:\n",
    "        # Manual labels do not exist. Run vertebrae labeling.\n",
    "        print(f\"{subject}: Manual labels not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.111814Z",
     "iopub.status.busy": "2024-10-27T14:54:00.111394Z",
     "iopub.status.idle": "2024-10-27T14:54:00.118834Z",
     "shell.execute_reply": "2024-10-27T14:54:00.118287Z"
    },
    "papermill": {
     "duration": 0.015086,
     "end_time": "2024-10-27T14:54:00.120174",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.105088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crop MP2RAGE for faster processing and better registration results\n",
    "dilation_kernel=\"20x20x0\"\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"anat\"))\n",
    "    !sct_crop_image -i {subject}_inv-1_part-mag_MP2RAGE.nii.gz -m {subject}_UNIT1_seg.nii.gz -dilate {dilation_kernel} -o {subject}_inv-1_part-mag_MP2RAGE_crop.nii.gz \n",
    "    !sct_crop_image -i {subject}_UNIT1.nii.gz -m {subject}_UNIT1_seg.nii.gz -dilate {dilation_kernel} -o {subject}_UNIT1_crop.nii.gz\n",
    "    !sct_crop_image -i {subject}_UNIT1_seg.nii.gz -m {subject}_UNIT1_seg.nii.gz -dilate {dilation_kernel} -o {subject}_UNIT1_seg_crop.nii.gz\n",
    "    !sct_crop_image -i {subject}_UNIT1_seg_labeled.nii.gz -m {subject}_UNIT1_seg.nii.gz -dilate {dilation_kernel} -o {subject}_UNIT1_seg_labeled_crop.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "papermill": {
     "duration": 0.005465,
     "end_time": "2024-10-27T14:54:00.131371",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.125906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Register spinal cord segmentation and labels to TFL and DREAM flip angle maps and SNR maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.143997Z",
     "iopub.status.busy": "2024-10-27T14:54:00.143447Z",
     "iopub.status.idle": "2024-10-27T14:54:00.149425Z",
     "shell.execute_reply": "2024-10-27T14:54:00.148799Z"
    },
    "papermill": {
     "duration": 0.013779,
     "end_time": "2024-10-27T14:54:00.150782",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.137003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Segment spinal cord on TFL data (B1+ mapping) â³\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    fname_manual_seg = os.path.join(path_labels, subject, \"fmap\", f\"{subject}_acq-anat_TB1TFL_label-SC_seg.nii.gz\")\n",
    "    if os.path.exists(fname_manual_seg):\n",
    "        # Manual segmentation already exists. Copy it to local folder\n",
    "        print(f\"{subject}: Manual segmentation found\\n\")\n",
    "        shutil.copyfile(fname_manual_seg, f\"{subject}_acq-anat_TB1TFL_seg.nii.gz\")\n",
    "        # Generate QC report to make sure the manual segmentation is correct\n",
    "        !sct_qc -i \"{subject}_acq-anat_TB1TFL.nii.gz\" -s \"{subject}_acq-anat_TB1TFL_seg.nii.gz\" -p sct_deepseg_sc -qc {path_qc} -qc-subject {subject}\n",
    "    else:\n",
    "        # Manual segmentation does not exist. Run automatic segmentation.\n",
    "        print(f\"{subject}: Manual segmentation not found\")\n",
    "        #EAO: remove -qc {path_qc} because its giving me an error\n",
    "        !sct_deepseg -i \"{subject}_acq-anat_TB1TFL.nii.gz\" -task seg_sc_contrast_agnostic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.163119Z",
     "iopub.status.busy": "2024-10-27T14:54:00.162633Z",
     "iopub.status.idle": "2024-10-27T14:54:00.171034Z",
     "shell.execute_reply": "2024-10-27T14:54:00.170402Z"
    },
    "papermill": {
     "duration": 0.016068,
     "end_time": "2024-10-27T14:54:00.172418",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.156350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Register TFL data (B1+ mapping) to the MP2RAGE scan â³\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    if subject==\"sub-CRMBM2\" or subject==\"sub-MPI2\":\n",
    "        #https://github.com/spinal-cord-7t/coil-qc-code/issues/48\n",
    "        !sct_register_multimodal -i {subject}_acq-anat_TB1TFL.nii.gz -iseg {subject}_acq-anat_TB1TFL_seg.nii.gz -d ../anat/{subject}_UNIT1_crop.nii.gz -dseg ../anat/{subject}_UNIT1_seg_crop.nii.gz -param step=1,type=seg,algo=centermass -qc \"{path_qc}\"\n",
    "    else:\n",
    "        if subject=='sub-MSSM1' or subject=='sub-MSSM2' or subject=='sub-MSSM3':\n",
    "            #https://github.com/spinal-cord-7t/coil-qc-code/issues/43\n",
    "            !sct_register_multimodal -i {subject}_acq-famp_TB1TFL.nii.gz -iseg {subject}_acq-anat_TB1TFL_seg.nii.gz -d ../anat/{subject}_inv-1_part-mag_MP2RAGE_crop.nii.gz -dseg ../anat/{subject}_UNIT1_seg_crop.nii.gz -param step=1,type=seg,algo=centermass -qc \"{path_qc}\"\n",
    "        else:\n",
    "            !sct_register_multimodal -i {subject}_acq-anat_TB1TFL.nii.gz -iseg {subject}_acq-anat_TB1TFL_seg.nii.gz -d ../anat/{subject}_inv-1_part-mag_MP2RAGE_crop.nii.gz -dseg ../anat/{subject}_UNIT1_seg_crop.nii.gz -param step=1,type=seg,algo=centermass -qc \"{path_qc}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.184865Z",
     "iopub.status.busy": "2024-10-27T14:54:00.184335Z",
     "iopub.status.idle": "2024-10-27T14:54:00.188380Z",
     "shell.execute_reply": "2024-10-27T14:54:00.187813Z"
    },
    "papermill": {
     "duration": 0.011622,
     "end_time": "2024-10-27T14:54:00.189723",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.178101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Register DREAM data (B1+ mapping) to the MP2RAGE scan â³\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    !sct_register_multimodal -i {subject}_acq-famp_TB1DREAM.nii.gz -d ../anat/{subject}_UNIT1_crop.nii.gz -dseg ../anat/{subject}_UNIT1_seg_crop.nii.gz -param step=1,type=im,algo=slicereg,metric=CC,smooth=1 -qc \"{path_qc}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.202003Z",
     "iopub.status.busy": "2024-10-27T14:54:00.201657Z",
     "iopub.status.idle": "2024-10-27T14:54:00.207827Z",
     "shell.execute_reply": "2024-10-27T14:54:00.207279Z"
    },
    "papermill": {
     "duration": 0.0138,
     "end_time": "2024-10-27T14:54:00.209127",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.195327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Register Rx coilQA data (SNR, g-factor) to the MP2RAGE scan â³\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    # Split SNR data into sub-volumes (https://github.com/spinal-cord-7t/coil-qc-code/issues/34)\n",
    "    !sct_image -i {subject}_acq-coilQaSagLarge_SNR.nii.gz -split t -o {subject}_acq-coilQaSagLarge_SNR.nii.gz\n",
    "    # Segment spinal cord on SNR map\n",
    "    #EAO: remove -qc {path_qc} because its giving me an error\n",
    "    !sct_deepseg -i {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -task seg_sc_contrast_agnostic \n",
    "    # Use the 1st volume of the SNR data, which corresponds to the sum-of-square SNR reconstruction\n",
    "    !sct_register_multimodal -i {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -d ../anat/{subject}_UNIT1_crop.nii.gz -iseg {subject}_acq-coilQaSagLarge_SNR_T0000_seg.nii.gz -dseg ../anat/{subject}_UNIT1_seg_crop.nii.gz -param step=1,type=seg,algo=centermass -qc \"{path_qc}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.221341Z",
     "iopub.status.busy": "2024-10-27T14:54:00.220986Z",
     "iopub.status.idle": "2024-10-27T14:54:00.282802Z",
     "shell.execute_reply": "2024-10-27T14:54:00.282119Z"
    },
    "papermill": {
     "duration": 0.069688,
     "end_time": "2024-10-27T14:54:00.284386",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.214698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Warping spinal cord segmentation and vertebral level to each flip angle and SNR map\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    \n",
    "    # Warping SC segmentation and vertebral levels to TFL fmaps \n",
    "    if subject==\"sub-CRMBM2\" or subject==\"sub-MPI2\":\n",
    "        #https://github.com/spinal-cord-7t/coil-qc-code/issues/48\n",
    "        !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_crop.nii.gz -d {subject}_acq-famp_TB1TFL.nii.gz -w warp_{subject}_UNIT1_crop2{subject}_acq-anat_TB1TFL.nii.gz -x linear -o {subject}_acq-famp_TB1TFL_seg.nii.gz\n",
    "        !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_labeled_crop.nii.gz -d {subject}_acq-famp_TB1TFL.nii.gz -w warp_{subject}_UNIT1_crop2{subject}_acq-anat_TB1TFL.nii.gz -x nn -o {subject}_acq-famp_TB1TFL_seg_labeled.nii.gz\n",
    "        \n",
    "    elif subject=='sub-MSSM1' or subject=='sub-MSSM2' or subject=='sub-MSSM3':   \n",
    "        #https://github.com/spinal-cord-7t/coil-qc-code/issues/43\n",
    "        !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_crop.nii.gz -d {subject}_acq-famp_TB1TFL.nii.gz -w warp_{subject}_inv-1_part-mag_MP2RAGE_crop2{subject}_acq-famp_TB1TFL.nii.gz -x linear -o {subject}_acq-famp_TB1TFL_seg.nii.gz\n",
    "        !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_labeled_crop.nii.gz -d {subject}_acq-famp_TB1TFL.nii.gz -w warp_{subject}_inv-1_part-mag_MP2RAGE_crop2{subject}_acq-famp_TB1TFL.nii.gz -x nn -o {subject}_acq-famp_TB1TFL_seg_labeled.nii.gz\n",
    "        \n",
    "    else:\n",
    "        !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_crop.nii.gz -d {subject}_acq-famp_TB1TFL.nii.gz -w warp_{subject}_inv-1_part-mag_MP2RAGE_crop2{subject}_acq-anat_TB1TFL.nii.gz -x linear -o {subject}_acq-famp_TB1TFL_seg.nii.gz\n",
    "        !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_labeled_crop.nii.gz -d {subject}_acq-famp_TB1TFL.nii.gz -w warp_{subject}_inv-1_part-mag_MP2RAGE_crop2{subject}_acq-anat_TB1TFL.nii.gz -x nn -o {subject}_acq-famp_TB1TFL_seg_labeled.nii.gz\n",
    "        \n",
    "    !sct_qc -i {subject}_acq-famp_TB1TFL.nii.gz -s {subject}_acq-famp_TB1TFL_seg.nii.gz -p sct_deepseg_sc -qc {path_qc} -qc-subject {subject}\n",
    "    !sct_qc -i {subject}_acq-famp_TB1TFL.nii.gz -s {subject}_acq-famp_TB1TFL_seg_labeled.nii.gz -p sct_label_vertebrae -qc {path_qc} -qc-subject {subject}\n",
    "    \n",
    "    # Warping SC segmentation and vertebral levels to DREAM fmaps \n",
    "    !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_crop.nii.gz -d {subject}_acq-famp_TB1DREAM.nii.gz -w warp_{subject}_UNIT1_crop2{subject}_acq-famp_TB1DREAM.nii.gz -x linear -o {subject}_acq-famp_TB1DREAM_seg.nii.gz\n",
    "    !sct_qc -i {subject}_acq-famp_TB1DREAM.nii.gz -s {subject}_acq-famp_TB1DREAM_seg.nii.gz -p sct_deepseg_sc -qc {path_qc} -qc-subject {subject}\n",
    "    \n",
    "    !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_labeled_crop.nii.gz -d {subject}_acq-famp_TB1DREAM.nii.gz -w warp_{subject}_UNIT1_crop2{subject}_acq-famp_TB1DREAM.nii.gz -x nn -o {subject}_acq-famp_TB1DREAM_seg_labeled.nii.gz\n",
    "    !sct_qc -i {subject}_acq-famp_TB1DREAM.nii.gz -s {subject}_acq-famp_TB1DREAM_seg_labeled.nii.gz -p sct_label_vertebrae -qc {path_qc} -qc-subject {subject}\n",
    "    \n",
    "    # Warping SC segmentation and vertebral level to SNR maps\n",
    "    !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_crop.nii.gz -d {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -w warp_{subject}_UNIT1_crop2{subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -x linear -o {subject}_acq-coilQaSagLarge_SNR_T0000_seg.nii.gz\n",
    "    !sct_qc -i {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -s {subject}_acq-coilQaSagLarge_SNR_T0000_seg.nii.gz -p sct_deepseg_sc -qc {path_qc} -qc-subject {subject}\n",
    "    \n",
    "    !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_labeled_crop.nii.gz -d {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -w warp_{subject}_UNIT1_crop2{subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -x nn -o {subject}_acq-coilQaSagLarge_SNR_T0000_seg_labeled.nii.gz\n",
    "    !sct_qc -i {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -s {subject}_acq-coilQaSagLarge_SNR_T0000_seg_labeled.nii.gz -p sct_label_vertebrae -qc {path_qc} -qc-subject {subject}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "papermill": {
     "duration": 0.00566,
     "end_time": "2024-10-27T14:54:00.296042",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.290382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Convert TFL and DREAM flip angle maps to B1+ in units of nT/V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.309511Z",
     "iopub.status.busy": "2024-10-27T14:54:00.309093Z",
     "iopub.status.idle": "2024-10-27T14:54:00.379627Z",
     "shell.execute_reply": "2024-10-27T14:54:00.378983Z"
    },
    "papermill": {
     "duration": 0.079358,
     "end_time": "2024-10-27T14:54:00.381010",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.301652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load DREAM FA maps acquired with different reference voltages\n",
    "# threshold FA maps to 20deg < FA < 50deg\n",
    "# combine FA maps by averaging non-zero estimates of FA in each pixel\n",
    "\n",
    "GAMMA = 2.675e8;  # [rad / (s T)]\n",
    "voltages = [\"1.5\", \"0.66\"]\n",
    "\n",
    "for subject in subjects:\n",
    "    \n",
    "    b1_maps = []\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "\n",
    "    if subject=='sub-MSSM1':\n",
    "        ref_voltage=450\n",
    "    elif subject=='sub-MSSM2':\n",
    "        ref_voltage=350\n",
    "    elif subject=='sub-MSSM3':\n",
    "        ref_voltage=450\n",
    "    else:     \n",
    "        # Fetch the reference voltage from the JSON sidecar \n",
    "        with open(f\"{subject}_acq-famp_TB1DREAM.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "            ref_voltage = metadata.get(\"TxRefAmp\", \"N/A\")\n",
    "            if (ref_voltage == \"N/A\"):\n",
    "                ref_token = \"N/A\"\n",
    "                for token in metadata.get(\"SeriesDescription\", \"N/A\").split(\"_\"):\n",
    "                    if token.startswith(\"RefV\"): ref_token = token\n",
    "                ref_voltage = float(ref_token[4:-1])\n",
    "    \n",
    "    # Open refV flip angle map with nibabel\n",
    "    nii = nib.load(f\"{subject}_acq-famp_TB1DREAM.nii.gz\")\n",
    "    meas_fa = nii.get_fdata()\n",
    "    #thresholding\n",
    "    meas_fa[meas_fa < 200] = np.nan\n",
    "    meas_fa[meas_fa > 500] = np.nan\n",
    "\n",
    "    # Fetch the flip angle from the JSON sidecar \n",
    "    with open(f\"{subject}_acq-famp_TB1DREAM.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        requested_fa = metadata.get(\"FlipAngle\", \"N/A\")\n",
    "        #convert measured FA to percent of requested FA (note that measured FA map is in degrees * 10)\n",
    "        meas_fa = (meas_fa/10) / requested_fa\n",
    "\n",
    "    # Account for the power loss between the coil and the socket. That number was given by Siemens.\n",
    "    voltage_at_socket = ref_voltage * 10 ** -0.095\n",
    "    # Compute B1 map in [T/V]\n",
    "    b1_map = meas_fa * (np.pi / (GAMMA * 1e-3 * voltage_at_socket))\n",
    "    # Convert to [nT/V]\n",
    "    b1_map = b1_map * 1e9\n",
    "    \n",
    "    b1_maps.append(b1_map)\n",
    "\n",
    "    for voltage in voltages:\n",
    "        \n",
    "        #check if map exists\n",
    "        my_file = Path(f\"{subject}_acq-famp-{voltage}_TB1DREAM.nii.gz\")\n",
    "        \n",
    "        if my_file.is_file():\n",
    "            \n",
    "            if subject=='sub-MSSM2' and voltage==\"1.5\":\n",
    "                ref_voltage=450\n",
    "            elif subject=='sub-MSSM2' and voltage==\"0.66\":\n",
    "                ref_voltage=234\n",
    "            elif subject=='sub-MSSM3' and voltage==\"0.66\":\n",
    "                ref_voltage=328\n",
    "            else:            \n",
    "                # Fetch the reference voltage from the JSON sidecar \n",
    "                with open(f\"{subject}_acq-famp-{voltage}_TB1DREAM.json\", \"r\") as f:\n",
    "                    metadata = json.load(f)\n",
    "                    ref_voltage = metadata.get(\"TxRefAmp\", \"N/A\")\n",
    "                    if (ref_voltage == \"N/A\"):\n",
    "                        ref_token = \"N/A\"\n",
    "                        for token in metadata.get(\"SeriesDescription\", \"N/A\").split(\"_\"):\n",
    "                            if token.startswith(\"RefV\"): ref_token = token\n",
    "                        ref_voltage = float(ref_token[4:-1])\n",
    "                \n",
    "            # Open flip angle map with nibabel\n",
    "            nii = nib.load(f\"{subject}_acq-famp-{voltage}_TB1DREAM.nii.gz\")\n",
    "            meas_fa = nii.get_fdata()\n",
    "            #thresholding\n",
    "            meas_fa[meas_fa < 200] = np.nan\n",
    "            meas_fa[meas_fa > 500] = np.nan\n",
    "        \n",
    "            # Fetch the flip angle from the JSON sidecar \n",
    "            with open(f\"{subject}_acq-famp-{voltage}_TB1DREAM.json\", \"r\") as f:\n",
    "                metadata = json.load(f)\n",
    "                requested_fa = metadata.get(\"FlipAngle\", \"N/A\")\n",
    "                #convert measured FA to percent of requested FA (note that measured FA map is in degrees * 10)\n",
    "                meas_fa = (meas_fa/10) / requested_fa\n",
    "        else:\n",
    "            meas_fa = np.full((nii.header).get_data_shape(),np.nan)\n",
    "\n",
    "        # Account for the power loss between the coil and the socket. That number was given by Siemens.\n",
    "        voltage_at_socket = ref_voltage * 10 ** -0.095\n",
    "        # Compute B1 map in [T/V]\n",
    "        # Siemens maps are in units of flip angle * 10 (in degrees)\n",
    "        b1_map = meas_fa * (np.pi / (GAMMA * 1e-3 * voltage_at_socket))\n",
    "        # Convert to [nT/V]\n",
    "        b1_map = b1_map * 1e9\n",
    "        \n",
    "        b1_maps.append(b1_map)\n",
    " \n",
    "    # compute mean of non-zero values\n",
    "    avgB1=np.nanmean(b1_maps,axis=0)\n",
    "    \n",
    "    # Save as NIfTI file\n",
    "    nii_avgB1 = nib.Nifti1Image(avgB1, nii.affine, nii.header)\n",
    "    nib.save(nii_avgB1, f\"{subject}_DREAMTB1avgB1map.nii.gz\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.393974Z",
     "iopub.status.busy": "2024-10-27T14:54:00.393523Z",
     "iopub.status.idle": "2024-10-27T14:54:00.400651Z",
     "shell.execute_reply": "2024-10-27T14:54:00.400037Z"
    },
    "papermill": {
     "duration": 0.015006,
     "end_time": "2024-10-27T14:54:00.402003",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.386997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the TFL flip angle maps to B1+ efficiency maps [nT/V] (inspired by code from Kyle Gilbert)\n",
    "# The approach consists in calculating the B1+ efficiency using a 1ms, pi-pulse at the acquisition voltage,\n",
    "# then scale the efficiency by the ratio of the measured flip angle to the requested flip angle in the pulse sequence.\n",
    "\n",
    "GAMMA = 2.675e8;  # [rad / (s T)]\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "\n",
    "    if subject=='sub-MSSM1':\n",
    "        ref_voltage=450\n",
    "    elif subject=='sub-MSSM2':\n",
    "        ref_voltage=350\n",
    "    elif subject=='sub-MSSM3':\n",
    "        ref_voltage=450\n",
    "    else:     \n",
    "        # Fetch the reference voltage from the JSON sidecar \n",
    "        with open(f\"{subject}_acq-famp_TB1TFL.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "            ref_voltage = metadata.get(\"TxRefAmp\", \"N/A\")\n",
    "            if (ref_voltage == \"N/A\"):\n",
    "                ref_token = \"N/A\"\n",
    "                for token in metadata.get(\"SeriesDescription\", \"N/A\").split(\"_\"):\n",
    "                    if token.startswith(\"RefV\"): ref_token = token\n",
    "                ref_voltage = float(ref_token[4:-1])\n",
    "        \n",
    "    print(f\"ref_voltage [V]: {ref_voltage} ({subject}_acq-famp_TB1TFL)\")\n",
    "                \n",
    "    # Fetch the flip angle from the JSON sidecar \n",
    "    with open(f\"{subject}_acq-famp_TB1TFL.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        requested_fa = metadata.get(\"FlipAngle\", \"N/A\")\n",
    "        print(f\"flip angle [degrees]: {requested_fa} ({subject}_acq-famp_TB1TFL)\")\n",
    "\n",
    "    # Open flip angle map with nibabel\n",
    "    nii = nib.load(f\"{subject}_acq-famp_TB1TFL.nii.gz\")\n",
    "    meas_fa = nii.get_fdata()\n",
    "\n",
    "    # Account for the power loss between the coil and the socket. That number was given by Siemens.\n",
    "    voltage_at_socket = ref_voltage * 10 ** -0.095\n",
    "\n",
    "    # Compute B1 map in [T/V]\n",
    "    # Siemens maps are in units of flip angle * 10 (in degrees)\n",
    "    b1_map = ((meas_fa / 10) / requested_fa) * (np.pi / (GAMMA * 1e-3 * voltage_at_socket))\n",
    "\n",
    "    # Convert to [nT/V]\n",
    "    b1_map = b1_map * 1e9\n",
    "\n",
    "    # Save B1 map in [T/V] as NIfTI file\n",
    "    nii_b1 = nib.Nifti1Image(b1_map, nii.affine, nii.header)\n",
    "    nib.save(nii_b1, f\"{subject}_TFLTB1map.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "papermill": {
     "duration": 0.005754,
     "end_time": "2024-10-27T14:54:00.434657",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.428903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Extract B1+ and SNR along the spinal cord "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.447815Z",
     "iopub.status.busy": "2024-10-27T14:54:00.447308Z",
     "iopub.status.idle": "2024-10-27T14:54:00.465841Z",
     "shell.execute_reply": "2024-10-27T14:54:00.465272Z"
    },
    "papermill": {
     "duration": 0.026868,
     "end_time": "2024-10-27T14:54:00.467411",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.440543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract B1+ and SNR along the spinal cord between levels C3 and T2 (included) and save data to CSV files\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    \n",
    "    fname_result_b1plus = os.path.join(path_results, f\"{subject}_TFLTB1map.csv\")\n",
    "    # Dilate TFL-registered SC segmentation \n",
    "    if subject=='sub-MSSM1' or subject=='sub-MSSM2' or subject=='sub-MSSM3':\n",
    "        #https://github.com/spinal-cord-7t/coil-qc-code/issues/43\n",
    "        !sct_maths -i {subject}_acq-famp_TB1TFL_seg.nii.gz -o {subject}_acq-famp_TB1TFL_seg_dilated.nii.gz -dilate 3 -dim=2 -shape=disk\n",
    "    else:   \n",
    "        !sct_maths -i {subject}_acq-anat_TB1TFL_seg.nii.gz -o {subject}_acq-famp_TB1TFL_seg_dilated.nii.gz -dilate 3 -dim=2 -shape=disk\n",
    "    !sct_extract_metric -i {subject}_TFLTB1map.nii.gz -f {subject}_acq-famp_TB1TFL_seg_dilated.nii.gz -method wa -vert 1:9 -vertfile {subject}_acq-famp_TB1TFL_seg_labeled.nii.gz -perlevel 1 -o \"{fname_result_b1plus}\"     \n",
    "            \n",
    "    fname_result_b1plus = os.path.join(path_results, f\"{subject}_DREAMTB1avgB1map.csv\")\n",
    "    # Dilate DREAM-registered SC segmentation \n",
    "    !sct_maths -i {subject}_acq-famp_TB1DREAM_seg.nii.gz -o {subject}_acq-famp_TB1DREAM_seg_dilated.nii.gz -dilate 3 -dim=2 -shape=disk\n",
    "    !sct_extract_metric -i {subject}_DREAMTB1avgB1map.nii.gz -f {subject}_acq-famp_TB1DREAM_seg_dilated.nii.gz -method wa -vert 1:9 -vertfile {subject}_acq-famp_TB1DREAM_seg_labeled.nii.gz -perlevel 1 -o \"{fname_result_b1plus}\"\n",
    "    \n",
    "    fname_result_SNR = os.path.join(path_results, f\"{subject}_SNRmap.csv\")\n",
    "    # Dilate SNR-registered SC segmentation \n",
    "    !sct_maths -i {subject}_acq-coilQaSagLarge_SNR_T0000_seg.nii.gz -o {subject}_acq-coilQaSagLarge_SNR_T0000_seg_dilated.nii.gz -dilate 3 -dim=2 -shape=disk\n",
    "    !sct_extract_metric -i {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -f {subject}_acq-coilQaSagLarge_SNR_T0000_seg_dilated.nii.gz -method wa -vert 1:9 -vertfile {subject}_acq-coilQaSagLarge_SNR_T0000_seg_labeled.nii.gz -perlevel 1 -o \"{fname_result_SNR}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "papermill": {
     "duration": 0.00573,
     "end_time": "2024-10-27T14:54:00.479249",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.473519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load data and generate figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.492296Z",
     "iopub.status.busy": "2024-10-27T14:54:00.491724Z",
     "iopub.status.idle": "2024-10-27T14:54:00.494983Z",
     "shell.execute_reply": "2024-10-27T14:54:00.494402Z"
    },
    "papermill": {
     "duration": 0.011214,
     "end_time": "2024-10-27T14:54:00.496287",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.485073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# load data, interpolate to vertebral levels, and save to data structures\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.509405Z",
     "iopub.status.busy": "2024-10-27T14:54:00.508861Z",
     "iopub.status.idle": "2024-10-27T14:54:00.512485Z",
     "shell.execute_reply": "2024-10-27T14:54:00.511819Z"
    },
    "papermill": {
     "duration": 0.011464,
     "end_time": "2024-10-27T14:54:00.513772",
     "exception": false,
     "start_time": "2024-10-27T14:54:00.502308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reorder subjects so that identical coils are displayed side-by-side\n",
    "subjects = ['sub-CRMBM1', 'sub-CRMBM2', 'sub-CRMBM3', 'sub-UCL1', 'sub-UCL2', 'sub-UCL3', 'sub-MNI1', 'sub-MNI2', 'sub-MNI3', 'sub-MGH1', 'sub-MGH2', 'sub-MGH3', 'sub-MPI1', 'sub-MPI2', 'sub-MPI3', 'sub-NTNU1', 'sub-NTNU2', 'sub-NTNU3', 'sub-MSSM1', 'sub-MSSM2', 'sub-MSSM3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552cba99",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T14:54:00.526504Z",
     "iopub.status.busy": "2024-10-27T14:54:00.526103Z",
     "iopub.status.idle": "2024-10-27T14:54:00.795083Z",
     "shell.execute_reply": "2024-10-27T14:54:00.794189Z"
    },
    "papermill": {
     "duration": 0.276594,
     "end_time": "2024-10-27T14:54:00.796247",
     "exception": true,
     "start_time": "2024-10-27T14:54:00.519653",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/runner/work/coil-qc-code/coil-qc-code/data-human/sub-CRMBM1/fmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 58\u001b[0m\n\u001b[1;32m     53\u001b[0m data_type[site]\u001b[38;5;241m=\u001b[39m{}\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m (j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 58\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubjects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfmap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# Initialize list to collect data for this subject\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     subject_data \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/runner/work/coil-qc-code/coil-qc-code/data-human/sub-CRMBM1/fmap'"
     ]
    }
   ],
   "source": [
    "# Go back to root data folder\n",
    "os.chdir(os.path.join(path_data))\n",
    "\n",
    "def smooth_data(data, window_size=20):\n",
    "    \"\"\" Apply a simple moving average to smooth the data. \"\"\"\n",
    "    return uniform_filter1d(data, size=window_size, mode='nearest')\n",
    "\n",
    "# Fixed grid for x-axis\n",
    "x_grid = np.linspace(0, 1, 100)\n",
    "\n",
    "# z-slices corresponding to levels C3 to T2 on the PAM50 template. These will be used to scale the x-label of each subject.\n",
    "original_vector = np.array([985, 939, 907, 870, 833, 800, 769, 735, 692, 646])\n",
    "\n",
    "# Normalize the PAM50 z-slice numbers to the 1-0 range (to show inferior-superior instead of superior-inferior)\n",
    "min_val = original_vector.min()\n",
    "max_val = original_vector.max()\n",
    "normalized_vector = 1 - ((original_vector - min_val) / (max_val - min_val))\n",
    "\n",
    "# Use this normalized vector as x-ticks\n",
    "custom_xticks = normalized_vector\n",
    "\n",
    "# Vertebral level labels\n",
    "vertebral_levels = [\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \"C7\", \"T1\", \"T2\"]\n",
    "# Calculate midpoints for label positions\n",
    "label_positions = normalized_vector[:-1] + np.diff(normalized_vector) / 2\n",
    "\n",
    "sites = [\"CRMBM\", \"UCL\", \"MNI\", \"MGH\", \"MPI\", \"NTNU\", \"MSSM\"]\n",
    "\n",
    "# map types\n",
    "map_types = [\"TFLTB1\", \"DREAMTB1avgB1\", \"SNR\"]\n",
    "\n",
    "# Data storage for statistics\n",
    "TFLTB1_data_stats = []\n",
    "DREAMTB1avgB1_data_stats = []\n",
    "SNR_TB1_data_stats = []\n",
    "\n",
    "data_stats = [TFLTB1_data_stats, DREAMTB1avgB1_data_stats, SNR_TB1_data_stats]\n",
    "\n",
    "# Data storage \n",
    "TFLTB1_data = {}\n",
    "DREAMTB1avgB1_data = {}\n",
    "SNR_data = {}\n",
    "data = [TFLTB1_data, DREAMTB1avgB1_data, SNR_data]\n",
    "\n",
    "\n",
    "for map_type, data_stats_type, data_type in zip(map_types,data_stats,data):\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    for site in sites:\n",
    "\n",
    "        data_type[site]={}\n",
    "\n",
    "\n",
    "        while i < (j+3):\n",
    "\n",
    "            os.chdir(os.path.join(path_data, f\"{subjects[i]}\", \"fmap\"))\n",
    "\n",
    "            # Initialize list to collect data for this subject\n",
    "            subject_data = []\n",
    "\n",
    "            file_csv = os.path.join(path_results, f\"{subjects[i]}_{map_type}map.csv\")\n",
    "            df = pd.read_csv(file_csv)\n",
    "            wa_data = df['WA()']\n",
    "\n",
    "            # Compute stats on the non-resampled data (to avoid interpolation errors)\n",
    "            mean_data = np.mean(wa_data)\n",
    "            sd_data = np.std(wa_data)\n",
    "\n",
    "            # Normalize the x-axis to a 1-0 scale for each subject (to go from superior-inferior direction)\n",
    "            x_subject = np.linspace(1, 0, len(wa_data))\n",
    "\n",
    "            # Interpolate to the fixed grid\n",
    "            interp_func = interp1d(x_subject, wa_data, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
    "            resampled_data = interp_func(x_grid)\n",
    "\n",
    "            # Apply smoothing\n",
    "            smoothed_data = smooth_data(resampled_data)\n",
    "            subject_data.append(smoothed_data)\n",
    "\n",
    "            for resampled_data in subject_data:\n",
    "                data_type[site][subjects[i]]=resampled_data\n",
    "                \n",
    "            data_stats_type.append([site, subjects[i], mean_data, sd_data])\n",
    "\n",
    "            i += 1        \n",
    "        j += 3\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Normalize slice average SNR values by slice-average TFL B1+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Following https://onlinelibrary.wiley.com/doi/full/10.1002/mrm.27695; here we normalize SNR maps by sin(FA), where FA is the actual FA map for the GRE SNR scan\n",
    "# By normalizing we extrapolate to the SNR value that we would achive with FA = 90, ie, SNR_90 = SNR_meas/sin(FA_meas), which can be directly compated between RF coils\n",
    "\n",
    "# Since we do not have the FA_meas (for the SNR GRE scan), we will compute it from the ratio of the measured and requested FA in the TFL B1+ scan\n",
    "# FA_gre_meas = FA_gre_requested * (FA_TFL_meas/FA_TFL_requested)\n",
    "# FA_TFL_meas/FA_TFL_requested was previously computed to obtain the TFL B1+ efficiency (stored in \"data\"), we will reconvert TFL B1+ efficiency to the FA_TFL_meas/FA_TFL_requested ratio\n",
    "\n",
    "sites = [\"CRMBM\", \"UCL\", \"MNI\", \"MGH\", \"MPI\", \"NTNU\", \"MSSM\"]\n",
    "\n",
    "# SNR along the cord is stored in a dictionary (data) of dictionaries (?) that has an array associated with each element\n",
    "# The order of the dictionary is {'CRMBM': {'sub-CRMBM1': array([...]), 'sub-CRMBM2': array([...]), etc.\n",
    "# The 1st dictionary corresponds to the TFL B1+ data\n",
    "# The 3rd/last dictionary corresponds to the SNR data\n",
    "\n",
    "TFLB1_data = data[0]\n",
    "SNR_data = data[2]\n",
    "\n",
    "GAMMA = 2.675e8;  # [rad / (s T)]\n",
    "\n",
    "j = 0\n",
    "i = 0   \n",
    "for site in sites:   \n",
    "    while i < (j+3):\n",
    "\n",
    "        os.chdir(os.path.join(path_data, f\"{subjects[i]}\", \"fmap\"))\n",
    "\n",
    "        if subjects[i]=='sub-MSSM1':\n",
    "            ref_voltage=450\n",
    "        elif subjects[i]=='sub-MSSM2':\n",
    "            ref_voltage=350\n",
    "        elif subjects[i]=='sub-MSSM3':\n",
    "            ref_voltage=450\n",
    "        else:     \n",
    "            # Fetch the reference voltage from the JSON sidecar \n",
    "            with open(f\"{subjects[i]}_acq-famp_TB1TFL.json\", \"r\") as f:\n",
    "                metadata = json.load(f)\n",
    "                ref_voltage = metadata.get(\"TxRefAmp\", \"N/A\")\n",
    "                if (ref_voltage == \"N/A\"):\n",
    "                    ref_token = \"N/A\"\n",
    "                    for token in metadata.get(\"SeriesDescription\", \"N/A\").split(\"_\"):\n",
    "                        if token.startswith(\"RefV\"): ref_token = token\n",
    "                    ref_voltage = float(ref_token[4:-1])\n",
    "\n",
    "        # Account for the power loss between the coil and the socket. That number was given by Siemens.\n",
    "        voltage_at_socket = ref_voltage * 10 ** -0.095\n",
    "                \n",
    "        # Fetch the requested flip angle for the SNR(GRE) scan from the JSON sidecar \n",
    "        with open(f\"{subjects[i]}_acq-coilQaSagLarge_SNR.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "            requested_fa = metadata.get(\"FlipAngle\", \"N/A\")\n",
    "\n",
    "        # compute the actual flip angle for the SNR(GRE) scan \n",
    "        actual_fa = requested_fa * (TFLB1_data[site][subjects[i]]/1e9) * ((GAMMA * 1e-3 * voltage_at_socket)/np.pi)\n",
    "        # normalize the SNR data by the actual flip angle\n",
    "        data[2][site][subjects[i]] = SNR_data[site][subjects[i]]/np.sin(np.deg2rad(actual_fa))\n",
    "\n",
    "        i += 1       \n",
    "    j += 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# genetrate figures for B1+ and SNR along the cord\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sites = [\"CRMBM\", \"UCL\", \"MNI\", \"MGH\", \"MPI\", \"NTNU\", \"MSSM\"]\n",
    "subject_names = [\"Subject 1\", \"Subject 2\", \"Subject 3\", \"average\"]\n",
    "\n",
    "# figure types\n",
    "fig_types = [\"TFL B1+ efficiency [nT/V]\", \"DREAM B1+ efficiency [nT/V]\", \"SNR_90\"]\n",
    "    \n",
    "for data_type, data_stats_type, fig_type in zip(data,data_stats,fig_types):\n",
    "    \n",
    "    avg_data = {'CRMBM': 0, 'UCL': 0, 'MNI': 0, 'MGH': 0, 'MPI': 0, 'NTNU': 0, 'MSSM': 0}\n",
    "   \n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(1, len(sites), wspace=0)\n",
    "    axs = gs.subplots(sharex=True, sharey=True)\n",
    "    fig.set_size_inches(16, 6)\n",
    "\n",
    "    \n",
    "    j = 0\n",
    "    i = 0\n",
    "    \n",
    "    for k, site in enumerate(sites):    \n",
    "        while i < (j+3):\n",
    "\n",
    "            axs[k].plot(data_type[site][subjects[i]])\n",
    "\n",
    "            avg_data[site] += data_type[site][subjects[i]]\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        j += 3\n",
    "        \n",
    "        avg_data[site] = avg_data[site]/3\n",
    "        \n",
    "        axs[k].plot(avg_data[site],color=\"black\",linestyle='dashed',linewidth=1)\n",
    "        axs[k].set_title(sites[k])\n",
    "        axs[k].grid()\n",
    "    \n",
    "    axs[0].legend(subject_names,loc=\"upper right\")\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Vertebral Levels', ylabel=fig_type, xticks=100*label_positions, xticklabels=vertebral_levels)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='center')\n",
    "\n",
    "    if fig_type==\"SNR_90\":\n",
    "        ax.set_ylim(0, 1300)\n",
    "    else:\n",
    "        ax.set_ylim(0, 85)  \n",
    "        \n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# genetrate figures for B1+ and SNR CoV along the cord\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# figure types\n",
    "fig_types = [\"TFL B1+ CoV [nT/V] across C1-T2\", \"DREAM B1+ CoV [nT/V] across C1-T2\", \"SNR CoV [arb] across C1-T2\"]\n",
    "subject_names = [\"Subject 1\", \"Subject 2\", \"Subject 3\"]\n",
    "\n",
    "for data_stats_type, fig_type in zip(data_stats,fig_types):\n",
    "    \n",
    "    series = [data_stats_type[i::len(subject_names)] for i in range(len(subject_names))]\n",
    "    hline_x = np.arange(len(sites))\n",
    "    hline_width = 0.25\n",
    "\n",
    "    sub_cov = np.zeros((len(subject_names),len(sites)))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "    i = 0 \n",
    "    for subject_name, subject_series in zip(subject_names, series): \n",
    "        \n",
    "        ax.scatter(sites, [subject_series[k][3]/subject_series[k][2] for k in range(0,len(sites))], label=subject_name)\n",
    "\n",
    "        for j in range(len(sites)):\n",
    "            sub_cov[i][j] = subject_series[j][3]/subject_series[j][2]\n",
    "\n",
    "        i+=1\n",
    "    \n",
    "    plt.hlines(np.mean(sub_cov, axis=0),hline_x - hline_width/2, hline_x + hline_width/2, color=\"black\", label=\"Across subj. mean\")\n",
    "        \n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 0.5)     \n",
    "    ax.set_title(fig_type)\n",
    "\n",
    "    plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Load data and generate figures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "# generate figures for B1+, SNR, and 1/g-factor maps obtained at each site (for one representative subject)\n",
    "###########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First co-regsiter subjects across sites for better visualisation and flatten the spinal cord (ie, being it into the sagittal midline)\n",
    "\n",
    "sites = [\"CRMBM\", \"UCL\", \"MNI\", \"MGH\", \"MPI\", \"NTNU\", \"MSSM\"]\n",
    "subject_ids = [\"1\",\"2\",\"3\"]\n",
    "site_ref = 'CRMBM'\n",
    "\n",
    "file_names = [\"TFLTB1map\", \"DREAMTB1avgB1map\",\"acq-coilQaSagLarge_SNR_T0000\"]\n",
    "\n",
    "for subject_id in subject_ids:\n",
    "    for site in sites:\n",
    "        print(f\"ğŸ‘‰ PROCESSING: {site}{subject_id}\")\n",
    "        for file_name in file_names:\n",
    "            os.chdir(os.path.join(path_data, \"sub-\"+site+subject_id, \"fmap\"))\n",
    "            \n",
    "            if site == \"CRMBM\":\n",
    "                # Flatten the spinal cord in the sagittal plane\n",
    "                if file_name == \"TFLTB1map\":\n",
    "                    !sct_flatten_sagittal -i sub-{site}{subject_id}_{file_name}.nii.gz -s sub-{site}{subject_id}_acq-famp_TB1TFL_seg.nii.gz\n",
    "                elif file_name == \"DREAMTB1avgB1map\":\n",
    "                    !sct_flatten_sagittal -i sub-{site}{subject_id}_{file_name}.nii.gz -s sub-{site}{subject_id}_acq-famp_TB1DREAM_seg.nii.gz\n",
    "                else:\n",
    "                    !sct_flatten_sagittal -i sub-{site}{subject_id}_{file_name}.nii.gz -s sub-{site}{subject_id}_{file_name}_seg.nii.gz\n",
    "            else:\n",
    "                # Co-register data to reference subject, then flatten the spinal cord in the sagittal plane\n",
    "                if file_name == \"TFLTB1map\":\n",
    "                    !sct_register_multimodal -i sub-{site}{subject_id}_{file_name}.nii.gz -iseg sub-{site}{subject_id}_acq-famp_TB1TFL_seg.nii.gz -d ../../sub-{site_ref}{subject_id}/fmap/sub-{site_ref}{subject_id}_{file_name}.nii.gz -dseg ../../sub-{site_ref}{subject_id}/fmap/sub-{site_ref}{subject_id}_acq-famp_TB1TFL_seg.nii.gz -param step=1,type=seg,algo=centermassrot,metric=MeanSquares\n",
    "                    !sct_flatten_sagittal -i sub-{site}{subject_id}_{file_name}_reg.nii.gz -s sub-{site}{subject_id}_acq-famp_TB1TFL_seg.nii.gz\n",
    "                elif file_name == \"DREAMTB1avgB1map\":\n",
    "                    !sct_register_multimodal -i sub-{site}{subject_id}_{file_name}.nii.gz -iseg sub-{site}{subject_id}_acq-famp_TB1DREAM_seg.nii.gz -d ../../sub-{site_ref}{subject_id}/fmap/sub-{site_ref}{subject_id}_{file_name}.nii.gz -dseg ../../sub-{site_ref}{subject_id}/fmap/sub-{site_ref}{subject_id}_acq-famp_TB1DREAM_seg.nii.gz -param step=1,type=seg,algo=centermassrot,metric=MeanSquares\n",
    "                    !sct_flatten_sagittal -i sub-{site}{subject_id}_{file_name}_reg.nii.gz -s sub-{site}{subject_id}_acq-famp_TB1DREAM_seg.nii.gz\n",
    "                else:\n",
    "                    !sct_register_multimodal -i sub-{site}{subject_id}_{file_name}.nii.gz -iseg sub-{site}{subject_id}_{file_name}_seg.nii.gz -d ../../sub-{site_ref}{subject_id}/fmap/sub-{site_ref}{subject_id}_{file_name}.nii.gz -dseg ../../sub-{site_ref}{subject_id}/fmap/sub-{site_ref}{subject_id}_{file_name}_seg.nii.gz -param step=1,type=seg,algo=centermassrot,metric=MeanSquares\n",
    "                    !sct_flatten_sagittal -i sub-{site}{subject_id}_{file_name}_reg.nii.gz -s sub-{site}{subject_id}_{file_name}_seg.nii.gz\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sites = [\"CRMBM\", \"UCL\", \"MNI\", \"MGH\", \"MPI\", \"NTNU\", \"MSSM\"]\n",
    "\n",
    "# map types\n",
    "map_types = [\"TFLTB1map\", \"DREAMTB1avgB1map\", \"acq-coilQaSagLarge_SNR_T0000\"]\n",
    "\n",
    "# legend types\n",
    "legend_types = [\"[nT/V]\", \"[nT/V]\", \"[arb]\", \"[arb]\", \"[arb]\"]\n",
    "\n",
    "# Select individual subject to show\n",
    "ind_subject = '3'\n",
    "\n",
    "for map_type, legend_type in zip(map_types,legend_types):\n",
    "    \n",
    "    # Create a figure with multiple subplots\n",
    "    fig, axes = plt.subplots(2, 4)#, figsize=(10, 8))\n",
    "    font_size = 12\n",
    "    axes=axes.flatten() \n",
    "        \n",
    "    for i,site in enumerate(sites):\n",
    "        # Load data\n",
    "        os.chdir(os.path.join(path_data, f\"sub-{site}{ind_subject}\", \"fmap\"))\n",
    "\n",
    "        if site==\"CRMBM\":\n",
    "            #map=nib.load(f\"sub-{site}{ind_subject}_{map_type}_flatten.nii.gz\")\n",
    "            map=nib.load(f\"sub-{site}{ind_subject}_{map_type}.nii.gz\")\n",
    "        else:\n",
    "            #map=nib.load(f\"sub-{site}{ind_subject}_{map_type}_reg_flatten.nii.gz\")\n",
    "            map=nib.load(f\"sub-{site}{ind_subject}_{map_type}_reg.nii.gz\")\n",
    "        \n",
    "        if map_type==\"TFLTB1map\" and ind_subject == '1':\n",
    "            data=map.get_fdata()[31:82,43:93,round(map.get_fdata().shape[2]/2)]\n",
    "        elif map_type==\"TFLTB1map\" and ind_subject == '2':\n",
    "            data=map.get_fdata()[28:71,37:94,round(map.get_fdata().shape[2]/2)]\n",
    "        elif map_type==\"TFLTB1map\" and ind_subject == '3':\n",
    "            data=map.get_fdata()[28:77,37:98,round(map.get_fdata().shape[2]/2)]\n",
    "        elif map_type==\"DREAMTB1avgB1map\" and ind_subject == '1':\n",
    "            data=map.get_fdata()[29:60,13:66,round(map.get_fdata().shape[2]/2)]\n",
    "        elif map_type==\"DREAMTB1avgB1map\" and ind_subject == '2':\n",
    "            data=map.get_fdata()[20:65,6:56,round(map.get_fdata().shape[2]/2)]\n",
    "        elif map_type==\"DREAMTB1avgB1map\" and ind_subject == '3':\n",
    "            data=map.get_fdata()[25:72,0:60,round(map.get_fdata().shape[2]/2)]\n",
    "        elif map_type==\"acq-coilQaSagLarge_SNR_T0000\" and ind_subject == '1':\n",
    "            data=map.get_fdata()[224:302,213:292,round(map.get_fdata().shape[2]/2)]\n",
    "        elif map_type==\"acq-coilQaSagLarge_SNR_T0000\" and ind_subject == '2':\n",
    "            data=map.get_fdata()[224:302,197:289,round(map.get_fdata().shape[2]/2)]\n",
    "        elif map_type==\"acq-coilQaSagLarge_SNR_T0000\" and ind_subject == '3':\n",
    "            data=map.get_fdata()[224:302,195:299,round(map.get_fdata().shape[2]/2)]\n",
    "    \n",
    "        axes[-1].axis('off') \n",
    "        # Defining dynamic range\n",
    "        axes[-1].axis('off')            \n",
    "        dynmin = 0 \n",
    "        if map_type==\"acq-coilQaSagLarge_SNR_T0000\":\n",
    "            dynmax = 230\n",
    "        else:\n",
    "            dynmax = 60    \n",
    "            \n",
    "        splot=axes[i]\n",
    "        im = splot.imshow((data.T), cmap='viridis', origin='lower',vmin=dynmin,vmax=dynmax)\n",
    "        \n",
    "        splot.set_title(site, size=font_size)\n",
    "        splot.axis('off')\n",
    "\n",
    "    # If map_type is B1+ or SNR, and in-vivo subject, then the last subplot will be an anatomical scan with the dialted SC segmentation overlaid onto it\n",
    "    #if (map_type == \"TFLTB1map\" or map_type == \"DREAMTB1avgB1map\" or map_type == \"acq-coilQaSagLarge_SNR_T0000\") and ind_subject != '4':\n",
    "\n",
    "        #os.chdir(os.path.join(path_data, f\"sub-{sites[0]}{ind_subject}\", \"fmap\"))\n",
    "        # Load data\n",
    "        #map=nib.load(f\"sub-{sites[0]}{ind_subject}_acq-anat_TB1TFL.nii.gz\")\n",
    "        #data=map.get_fdata()[:,:,round(map.get_fdata().shape[2]/2)]\n",
    "        #splot=axes[-1]\n",
    "        #splot.imshow((data.T), cmap='gray', origin='lower',vmin=0,vmax=2000)\n",
    "        #splot.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #plt.subplots_adjust(wspace=0.1, hspace=0.1, right=0.9)\n",
    "\n",
    "    # Colorbar\n",
    "    # Assume that the colorbar should start at the bottom of the lower row of subplots and\n",
    "    # extend to the top of the upper row of subplots\n",
    "    cbar_bottom = 0.25  # This might need adjustment\n",
    "    cbar_height = 0.5  # This represents the total height of both rows of subplots\n",
    "    cbar_dist = 1.01\n",
    "    cbar_ax = fig.add_axes([cbar_dist, cbar_bottom, 0.03, cbar_height])\n",
    "    cbar = plt.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "    cbar_ax.set_title(legend_type, size=12)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sites = [\"CRMBM\", \"MNI\", \"MPI\", \"MSSM\", \"UCL\", \"MGH\", \"NTNU\"]\n",
    "\n",
    "# map types\n",
    "map_types = [\"acq-coilQaSagSmall_GFactor\", \"T2starw\"]\n",
    "\n",
    "# legend types\n",
    "legend_types = [\"1/g\", \"[arb]\"]\n",
    "\n",
    "# Select individual subject to show\n",
    "ind_subject = '2'\n",
    "\n",
    "mean_gfac = {}\n",
    "max_gfac = {}\n",
    "\n",
    "for map_type, legend_type in zip(map_types,legend_types):\n",
    "    \n",
    "    # Create a figure with multiple subplots\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(10, 8))\n",
    "    font_size = 12\n",
    "    axes=axes.flatten() \n",
    "        \n",
    "    for i,site in enumerate(sites):\n",
    "        # Load data\n",
    "        if map_type==\"T2starw\":\n",
    "            os.chdir(os.path.join(path_data, f\"sub-{site}{ind_subject}\", \"anat\"))\n",
    "            map=nib.load(f\"sub-{site}{ind_subject}_{map_type}.nii.gz\")\n",
    "            data=map.get_fdata()[:,:,round(map.get_fdata().shape[2]/2)]\n",
    "        else:         \n",
    "            os.chdir(os.path.join(path_data, f\"sub-{site}{ind_subject}\", \"fmap\"))\n",
    "            map=nib.load(f\"sub-{site}{ind_subject}_{map_type}.nii.gz\")\n",
    "            # The 4th dimension inlcudes 12 acceleration maps: \n",
    "            #['R 2','R 3', 'R 4', 'R 6', 'R 8', 'R 2 x 2', 'R 2 x 3', 'R 3 x 2', 'R 3 x 3', 'R 3 x 4', 'R 4 x 3', 'R 4 x 4']\n",
    "            # show the R = 2 x 2 map\n",
    "            data=(map.get_fdata()[64:191,64:191,round(map.get_fdata().shape[2]/2),5])/1000\n",
    "            gfac_data=(map.get_fdata()[round(map.get_fdata().shape[0]/2)-10:round(map.get_fdata().shape[0]/2)+10,round(map.get_fdata().shape[1]/2)-10:round(map.get_fdata().shape[1]/2)+10,round(map.get_fdata().shape[2]/2),5])\n",
    "            mean_gfac[site]=np.nanmean(gfac_data)/1000\n",
    "            max_gfac[site]=np.max(gfac_data)/1000\n",
    "    \n",
    "        # Plot  \n",
    "        splot=axes[i]\n",
    "        dynmin = 0 \n",
    "        if map_type==\"acq-coilQaSagSmall_GFactor\":\n",
    "            dynmax = 1\n",
    "            axes[-1].axis('off')\n",
    "            splot.text(0, 3, r'mean 1/g='+str(round(mean_gfac[site],4)), size=10)\n",
    "            #splot.text(0, 12, r'max gfac='+str(round(max_gfac[site],3)), size=10)\n",
    "            \n",
    "            x = [data.shape[0]/2-10, data.shape[1]/2-10] \n",
    "            y = [data.shape[0]/2-10, data.shape[1]/2+10] \n",
    "            splot.plot(x, y, color=\"black\", linewidth=2) \n",
    "            \n",
    "            x = [data.shape[0]/2-10, data.shape[1]/2+10] \n",
    "            y = [data.shape[0]/2+10, data.shape[1]/2+10] \n",
    "            splot.plot(x, y, color=\"black\", linewidth=2) \n",
    "\n",
    "            x = [data.shape[0]/2+10, data.shape[1]/2+10] \n",
    "            y = [data.shape[0]/2+10, data.shape[1]/2-10] \n",
    "            splot.plot(x, y, color=\"black\", linewidth=2)\n",
    "\n",
    "            x = [data.shape[0]/2+10, data.shape[1]/2-10] \n",
    "            y = [data.shape[0]/2-10, data.shape[1]/2-10] \n",
    "            splot.plot(x, y, color=\"black\", linewidth=2) \n",
    "        else:\n",
    "            dynmax = 3000\n",
    "            axes[-1].axis('off') \n",
    "            \n",
    "        im = splot.imshow((data.T), cmap='viridis', origin='lower',vmin=dynmin,vmax=dynmax)  \n",
    "        splot.set_title(site, size=font_size)\n",
    "        splot.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Colorbar\n",
    "    # Assume that the colorbar should start at the bottom of the lower row of subplots and\n",
    "    # extend to the top of the upper row of subplots\n",
    "    cbar_bottom = 0.25  # This might need adjustment\n",
    "    cbar_height = 0.5  # This represents the total height of both rows of subplots\n",
    "    cbar_dist = 1.01\n",
    "    cbar_ax = fig.add_axes([cbar_dist, cbar_bottom, 0.03, cbar_height])\n",
    "    cbar = plt.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "    cbar_ax.set_title(legend_type, size=12)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "# generate tiled figure with individual channel GRE maps for a single subject at one site \n",
    "###########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sites = [\"CRMBM\", \"UCL\", \"MNI\", \"MGH\", \"MPI\", \"NTNU\", \"MSSM\"]\n",
    "\n",
    "# Select subject to show\n",
    "subject = '1'\n",
    "\n",
    "        \n",
    "for i,site in enumerate(sites):\n",
    "\n",
    "    gre_files=sorted(glob.glob(os.path.join(path_data, f\"sub-{site}{subject}\", \"anat\", '*uncombined*.nii.gz')))\n",
    "        \n",
    "    #Tiled figure in a five-row layout\n",
    "    rows=int(np.ceil(len(gre_files)/4))\n",
    "    cols=int(np.ceil(len(gre_files)/rows))\n",
    "\n",
    "    fig=plt.figure(figsize=(15, 20))\n",
    "    \n",
    "    ax = fig.subplots(rows,cols,squeeze=True)\n",
    "    \n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "\n",
    "            i = row*cols+col\n",
    "\n",
    "            if i < len(gre_files):\n",
    "            \n",
    "                #read in files\n",
    "                data_to_plot=(nib.load(gre_files[i])).get_fdata() #load in nifti object, get only image data\n",
    "                data_to_plot=np.rot90(data_to_plot[:,:,int(np.floor(data_to_plot.shape[2]/2))]) #central slice\n",
    "           \n",
    "                ax[row,col].imshow(data_to_plot,cmap=plt.cm.gray,clim=[0, 300])\n",
    "                ax[row,col].text(0.5, 0.05, 'Rx channel : ' + str(i+1),horizontalalignment='center', transform=ax[row,col].transAxes,color='white',fontsize=17)\n",
    "                ax[row,col].axis('off')\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(hspace=0,wspace=0)\n",
    "    fig.suptitle(site, fontsize=20, y=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Indicate duration of data processing\n",
    "\n",
    "end_time = datetime.now()\n",
    "total_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Convert seconds to a timedelta object\n",
    "total_time_delta = timedelta(seconds=total_time)\n",
    "\n",
    "# Format the timedelta object to a string\n",
    "formatted_time = str(total_time_delta)\n",
    "\n",
    "# Pad the string representation if less than an hour\n",
    "formatted_time = formatted_time.rjust(8, '0')\n",
    "\n",
    "print(f\"Total Runtime [hour:min:sec]: {formatted_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.183113,
   "end_time": "2024-10-27T14:54:01.118901",
   "environment_variables": {},
   "exception": true,
   "input_path": "./data_processing-human.ipynb",
   "output_path": "executed_notebooks/data_processing-human.ipynb",
   "parameters": {},
   "start_time": "2024-10-27T14:53:56.935788",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}