{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 7T coil comparison: processing of human data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7bce4",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from scipy.stats import iqr\n",
    "import shutil\n",
    "import zipfile\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Download data from OpenNeuro ⏳\n",
    "\n",
    "!openneuro-py download --dataset ds005025 --target-dir data-human/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define useful variables\n",
    "path_data = os.path.join(os.getcwd(), \"data-human/\")\n",
    "print(f\"path_data: {path_data}\")\n",
    "path_labels = os.path.join(path_data, \"derivatives\", \"labels\")\n",
    "path_qc = os.path.join(path_data, \"qc\")\n",
    "subjects = [os.path.basename(subject_path) for subject_path in sorted(glob.glob(os.path.join(path_data, \"sub-*\")))]\n",
    "print(f\"subjects: {subjects}\")\n",
    "\n",
    "# Create output folder\n",
    "path_results = os.path.join(path_data, \"derivatives\", \"results\")\n",
    "os.makedirs(path_results, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## MP2RAGE segmentation and vertebral labeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Run segmentation on MP2RAGE scan ⏳\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"anat\"))\n",
    "    fname_manual_seg = os.path.join(path_labels, subject, \"anat\", f\"{subject}_UNIT1_label-SC_seg.nii.gz\")\n",
    "    if os.path.exists(fname_manual_seg):\n",
    "        # Manual segmentation already exists. Copy it to local folder\n",
    "        print(f\"{subject}: Manual segmentation found\\n\")\n",
    "        shutil.copyfile(fname_manual_seg, f\"{subject}_UNIT1_seg.nii.gz\")\n",
    "        # Generate QC report to make sure the manual segmentation is correct\n",
    "        !sct_qc -i {subject}_UNIT1.nii.gz -s {subject}_UNIT1_seg.nii.gz -p sct_deepseg_sc -qc {path_qc} -qc-subject {subject}\n",
    "    else:\n",
    "        # Manual segmentation does not exist. Run automatic segmentation.\n",
    "        print(f\"{subject}: Manual segmentation not found\")\n",
    "        !sct_deepseg -i \"{subject}_UNIT1.nii.gz\" -task seg_sc_contrast_agnostic -thr 0 -qc {path_qc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Label vertebrae\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"anat\"))\n",
    "    fname_manual_labels = os.path.join(path_labels, subject, \"anat\", f\"{subject}_UNIT1_label-disc.nii.gz\")\n",
    "    if os.path.exists(fname_manual_labels):\n",
    "        # Use manual disc labels to generate labeled segmentation.\n",
    "        print(f\"{subject}: Manual labels found\\n\")\n",
    "        !sct_label_utils -i {subject}_UNIT1_seg.nii.gz -disc {fname_manual_labels} -o {subject}_UNIT1_seg_labeled.nii.gz\n",
    "        # Generate QC report to assess labeled segmentation\n",
    "        !sct_qc -i {subject}_UNIT1.nii.gz -s {subject}_UNIT1_seg_labeled.nii.gz -p sct_label_vertebrae -qc {path_qc} -qc-subject {subject}\n",
    "    else:\n",
    "        # Manual labels do not exist. They should!\n",
    "        print(f\"{subject}: Manual labels not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Crop MP2RAGE for faster processing and better registration results\n",
    "dilation_kernel=\"20x20x0\"\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"anat\"))\n",
    "    !sct_crop_image -i {subject}_inv-1_part-mag_MP2RAGE.nii.gz -m {subject}_UNIT1_seg.nii.gz -dilate {dilation_kernel} -o {subject}_inv-1_part-mag_MP2RAGE_crop.nii.gz \n",
    "    !sct_crop_image -i {subject}_UNIT1.nii.gz -m {subject}_UNIT1_seg.nii.gz -dilate {dilation_kernel} -o {subject}_UNIT1_crop.nii.gz\n",
    "    !sct_crop_image -i {subject}_UNIT1_seg.nii.gz -m {subject}_UNIT1_seg.nii.gz -dilate {dilation_kernel} -o {subject}_UNIT1_seg_crop.nii.gz\n",
    "    !sct_crop_image -i {subject}_UNIT1_seg_labeled.nii.gz -m {subject}_UNIT1_seg.nii.gz -dilate {dilation_kernel} -o {subject}_UNIT1_seg_labeled_crop.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Register MP2RAGE to B1+ and SNR data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e51379",
   "metadata": {},
   "source": [
    "### Segment spinal cord on TFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Segment spinal cord on TFL data (B1+ mapping) ⏳\n",
    "\n",
    "# Only do this for subjects without MSSM in their name (https://github.com/spinal-cord-7t/coil-qc-code/issues/153)\n",
    "subjects_without_MSSM = [subject for subject in subjects if \"MSSM\" not in subject]\n",
    "\n",
    "for subject in subjects_without_MSSM:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    fname_manual_seg = os.path.join(path_labels, subject, \"fmap\", f\"{subject}_acq-anat_TB1TFL_label-SC_seg.nii.gz\")\n",
    "    if os.path.exists(fname_manual_seg):\n",
    "        # Manual segmentation already exists. Copy it to local folder\n",
    "        print(f\"{subject}: Manual segmentation found\\n\")\n",
    "        shutil.copyfile(fname_manual_seg, f\"{subject}_acq-anat_TB1TFL_seg.nii.gz\")\n",
    "        # Generate QC report to make sure the manual segmentation is correct\n",
    "        if subject in ['sub-MSSM1', 'sub-MSSM2', 'sub-MSSM3']:\n",
    "            !sct_qc -i \"{subject}_acq-famp_TB1TFL.nii.gz\" -s \"{subject}_acq-anat_TB1TFL_seg.nii.gz\" -p sct_deepseg_sc -qc {path_qc} -qc-subject {subject}\n",
    "        else:\n",
    "            !sct_qc -i \"{subject}_acq-anat_TB1TFL.nii.gz\" -s \"{subject}_acq-anat_TB1TFL_seg.nii.gz\" -p sct_deepseg_sc -qc {path_qc} -qc-subject {subject}\n",
    "    else:\n",
    "        # Manual segmentation does not exist. Run automatic segmentation.\n",
    "        print(f\"{subject}: Manual segmentation not found\")\n",
    "        !sct_deepseg -i \"{subject}_acq-anat_TB1TFL.nii.gz\" -task seg_sc_contrast_agnostic -thr 0 -qc {path_qc} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b41953d",
   "metadata": {},
   "source": [
    "### Register TFL to MP2RAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Register TFL data (B1+ mapping) to the MP2RAGE scan ⏳\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    if subject in ['sub-MSSM1', 'sub-MSSM2', 'sub-MSSM3']:\n",
    "        # https://github.com/spinal-cord-7t/coil-qc-code/issues/43\n",
    "        # https://github.com/spinal-cord-7t/coil-qc-code/issues/153\n",
    "        !sct_register_multimodal -i {subject}_acq-famp_TB1TFL.nii.gz -d ../anat/{subject}_inv-1_part-mag_MP2RAGE_crop.nii.gz -dseg ../anat/{subject}_UNIT1_seg_crop.nii.gz -identity 1 -qc \"{path_qc}\"\n",
    "    else:\n",
    "        !sct_register_multimodal -i {subject}_acq-anat_TB1TFL.nii.gz -iseg {subject}_acq-anat_TB1TFL_seg.nii.gz -d ../anat/{subject}_inv-1_part-mag_MP2RAGE_crop.nii.gz -dseg ../anat/{subject}_UNIT1_seg_crop.nii.gz -param step=1,type=seg,algo=centermass -qc \"{path_qc}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915630fd",
   "metadata": {},
   "source": [
    "### Register DREAM to MP2RAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Register DREAM data (B1+ mapping) to the MP2RAGE scan ⏳\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    !sct_register_multimodal -i {subject}_acq-famp_TB1DREAM.nii.gz -d ../anat/{subject}_UNIT1_crop.nii.gz -dseg ../anat/{subject}_UNIT1_seg_crop.nii.gz -param step=1,type=im,algo=slicereg,metric=CC,smooth=1 -qc \"{path_qc}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401a6ca",
   "metadata": {},
   "source": [
    "### Segment spinal cord on SNR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Segment spinal cord on SNR data\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    # Split SNR data into sub-volumes (https://github.com/spinal-cord-7t/coil-qc-code/issues/34)\n",
    "    !sct_image -i {subject}_acq-coilQaSagLarge_SNR.nii.gz -split t -o {subject}_acq-coilQaSagLarge_SNR.nii.gz\n",
    "    # Crop SNR data (https://github.com/spinal-cord-7t/coil-qc-code/issues/128)\n",
    "    !sct_crop_image -i {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -xmax 450 -o {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz\n",
    "    !sct_crop_image -i {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -m {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -o {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz\n",
    "    # Segment spinal cord on SNR data, unless it already exists\n",
    "    fname_manual_seg = os.path.join(path_labels, subject, \"fmap\", f\"{subject}_acq-coilQaSagLarge_SNR_T0000_label-SC_seg.nii.gz\")\n",
    "    if os.path.exists(fname_manual_seg):\n",
    "        # Manual segmentation already exists. Copy it to local folder and put it in the same space as the SNR data\n",
    "        print(f\"{subject}: Manual segmentation found\\n\")\n",
    "        !sct_register_multimodal -i {fname_manual_seg} -d {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -o {subject}_acq-coilQaSagLarge_SNR_T0000_seg.nii.gz -identity 1 -x linear\n",
    "        # Generate QC report to make sure the manual segmentation is correct\n",
    "        !sct_qc -i \"{subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz\" -s \"{subject}_acq-coilQaSagLarge_SNR_T0000_seg.nii.gz\" -p sct_deepseg_sc -qc {path_qc} -qc-subject {subject}\n",
    "    else:\n",
    "        # Manual segmentation does not exist. Run automatic segmentation.\n",
    "        print(f\"{subject}: Manual segmentation not found\")\n",
    "        !sct_deepseg -i \"{subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz\" -task seg_sc_contrast_agnostic -thr 0 -qc {path_qc} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24d56d7",
   "metadata": {},
   "source": [
    "### Register SNR to MP2RAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Register Rx coilQA data (SNR, g-factor) to the MP2RAGE scan ⏳\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    !sct_register_multimodal -i {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -d ../anat/{subject}_inv-1_part-mag_MP2RAGE_crop.nii.gz -iseg {subject}_acq-coilQaSagLarge_SNR_T0000_seg.nii.gz -dseg ../anat/{subject}_UNIT1_seg_crop.nii.gz -param step=1,type=seg,algo=centermass -qc \"{path_qc}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d165a15c",
   "metadata": {},
   "source": [
    "### Warp MP2RAGE vertebral levels to fmap metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Warping vertebral level to each flip angle and SNR map\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    \n",
    "    # For MSSM subjects, we also need to warp the SC segmentation\n",
    "    if subject in ['sub-MSSM1', 'sub-MSSM2', 'sub-MSSM3']:\n",
    "        # Warping spinal cord segmentation to TFL data\n",
    "        !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_crop.nii.gz -d {subject}_acq-famp_TB1TFL.nii.gz -w warp_{subject}_inv-1_part-mag_MP2RAGE_crop2{subject}_acq-famp_TB1TFL.nii.gz -x linear -o {subject}_acq-anat_TB1TFL_seg.nii.gz\n",
    "        # Setting type to 'famp' for command below (https://github.com/spinal-cord-7t/coil-qc-code/issues/43)\n",
    "        type = 'famp'\n",
    "    else:\n",
    "        type = 'anat'\n",
    "    # Warping vertebral levels to TFL data\n",
    "    !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_labeled_crop.nii.gz -d {subject}_acq-famp_TB1TFL.nii.gz -w warp_{subject}_inv-1_part-mag_MP2RAGE_crop2{subject}_acq-{type}_TB1TFL.nii.gz -x nn -o {subject}_acq-anat_TB1TFL_seg_labeled-UNIT1reg.nii.gz\n",
    "    # !sct_qc -i {subject}_acq-{type}_TB1TFL.nii.gz -s {subject}_acq-anat_TB1TFL_seg_labeled-UNIT1reg.nii.gz -p sct_label_vertebrae -qc {path_qc} -qc-subject {subject}\n",
    "            \n",
    "    # Warping SC segmentation and vertebral levels to DREAM fmaps \n",
    "    !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_crop.nii.gz -d {subject}_acq-famp_TB1DREAM.nii.gz -w warp_{subject}_UNIT1_crop2{subject}_acq-famp_TB1DREAM.nii.gz -x linear -o {subject}_acq-famp_TB1DREAM_seg.nii.gz\n",
    "    # !sct_qc -i {subject}_acq-famp_TB1DREAM.nii.gz -s {subject}_acq-famp_TB1DREAM_seg.nii.gz -p sct_deepseg_sc -qc {path_qc} -qc-subject {subject}\n",
    "    !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_labeled_crop.nii.gz -d {subject}_acq-famp_TB1DREAM.nii.gz -w warp_{subject}_UNIT1_crop2{subject}_acq-famp_TB1DREAM.nii.gz -x nn -o {subject}_acq-famp_TB1DREAM_seg_labeled-UNIT1reg.nii.gz\n",
    "    # !sct_qc -i {subject}_acq-famp_TB1DREAM.nii.gz -s {subject}_acq-famp_TB1DREAM_seg_labeled-UNIT1reg.nii.gz -p sct_label_vertebrae -qc {path_qc} -qc-subject {subject}\n",
    "    \n",
    "    # Warping SC segmentation and vertebral level to SNR maps\n",
    "    !sct_apply_transfo -i ../anat/{subject}_UNIT1_seg_labeled_crop.nii.gz -d {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -w warp_{subject}_inv-1_part-mag_MP2RAGE_crop2{subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -x nn -o {subject}_acq-coilQaSagLarge_SNR_T0000_seg_labeled-UNIT1reg.nii.gz\n",
    "    # !sct_qc -i {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -s {subject}_acq-coilQaSagLarge_SNR_T0000_seg_labeled-UNIT1reg.nii.gz -p sct_label_vertebrae -qc {path_qc} -qc-subject {subject}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913487c7",
   "metadata": {},
   "source": [
    "### Quality control (local station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality control of registration\n",
    "\n",
    "# This code generates syntax to open the registered data in FSLeyes. The syntax should be run from within the `data-human/` folder.\n",
    "for subject in subjects:\n",
    "# for subject in ['sub-MGH1']:\n",
    "    print(f\"\\n👉 CHECKING REGISTRATION FOR: {subject}\\n\")\n",
    "    cmd = f\"fsleyes {subject}/fmap/{subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz {subject}/fmap/{subject}_acq-coilQaSagLarge_SNR_T0000_seg_labeled-UNIT1reg.nii.gz --cmap rainbow\"\n",
    "    print(cmd+\" &\")\n",
    "\n",
    "# TODO: undisplay all scans but the first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Convert TFL and DREAM flip angle maps to B1+ in units of nT/V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load DREAM FA maps acquired with different reference voltages\n",
    "# threshold FA maps to 20deg < FA < 50deg\n",
    "# combine FA maps by averaging non-zero estimates of FA in each pixel\n",
    "\n",
    "GAMMA = 2.675e8;  # [rad / (s T)]\n",
    "voltages = [\"1.5\", \"0.66\"]\n",
    "\n",
    "for subject in subjects:\n",
    "    \n",
    "    b1_maps = []\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "\n",
    "    if subject=='sub-MSSM1':\n",
    "        ref_voltage=450\n",
    "    elif subject=='sub-MSSM2':\n",
    "        ref_voltage=350\n",
    "    elif subject=='sub-MSSM3':\n",
    "        ref_voltage=450\n",
    "    else:     \n",
    "        # Fetch the reference voltage from the JSON sidecar \n",
    "        with open(f\"{subject}_acq-famp_TB1DREAM.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "            ref_voltage = metadata.get(\"TxRefAmp\", \"N/A\")\n",
    "            if (ref_voltage == \"N/A\"):\n",
    "                ref_token = \"N/A\"\n",
    "                for token in metadata.get(\"SeriesDescription\", \"N/A\").split(\"_\"):\n",
    "                    if token.startswith(\"RefV\"): ref_token = token\n",
    "                ref_voltage = float(ref_token[4:-1])\n",
    "    \n",
    "    # Open refV flip angle map with nibabel\n",
    "    nii = nib.load(f\"{subject}_acq-famp_TB1DREAM.nii.gz\")\n",
    "    meas_fa = nii.get_fdata()\n",
    "    #thresholding\n",
    "    meas_fa[meas_fa < 200] = np.nan\n",
    "    meas_fa[meas_fa > 500] = np.nan\n",
    "\n",
    "    # Fetch the flip angle from the JSON sidecar \n",
    "    with open(f\"{subject}_acq-famp_TB1DREAM.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        requested_fa = metadata.get(\"FlipAngle\", \"N/A\")\n",
    "        #convert measured FA to percent of requested FA (note that measured FA map is in degrees * 10)\n",
    "        meas_fa = (meas_fa/10) / requested_fa\n",
    "\n",
    "    # Account for the power loss between the coil and the socket. That number was given by Siemens.\n",
    "    voltage_at_socket = ref_voltage * 10 ** -0.095\n",
    "    # Compute B1 map in [T/V]\n",
    "    b1_map = meas_fa * (np.pi / (GAMMA * 1e-3 * voltage_at_socket))\n",
    "    # Convert to [nT/V]\n",
    "    b1_map = b1_map * 1e9\n",
    "    \n",
    "    b1_maps.append(b1_map)\n",
    "\n",
    "    for voltage in voltages:\n",
    "        \n",
    "        #check if map exists\n",
    "        my_file = Path(f\"{subject}_acq-famp-{voltage}_TB1DREAM.nii.gz\")\n",
    "        \n",
    "        if my_file.is_file():\n",
    "            \n",
    "            if subject=='sub-MSSM2' and voltage==\"1.5\":\n",
    "                ref_voltage=450\n",
    "            elif subject=='sub-MSSM2' and voltage==\"0.66\":\n",
    "                ref_voltage=234\n",
    "            elif subject=='sub-MSSM3' and voltage==\"0.66\":\n",
    "                ref_voltage=328\n",
    "            else:            \n",
    "                # Fetch the reference voltage from the JSON sidecar \n",
    "                with open(f\"{subject}_acq-famp-{voltage}_TB1DREAM.json\", \"r\") as f:\n",
    "                    metadata = json.load(f)\n",
    "                    ref_voltage = metadata.get(\"TxRefAmp\", \"N/A\")\n",
    "                    if (ref_voltage == \"N/A\"):\n",
    "                        ref_token = \"N/A\"\n",
    "                        for token in metadata.get(\"SeriesDescription\", \"N/A\").split(\"_\"):\n",
    "                            if token.startswith(\"RefV\"): ref_token = token\n",
    "                        ref_voltage = float(ref_token[4:-1])\n",
    "                \n",
    "            # Open flip angle map with nibabel\n",
    "            nii = nib.load(f\"{subject}_acq-famp-{voltage}_TB1DREAM.nii.gz\")\n",
    "            meas_fa = nii.get_fdata()\n",
    "            #thresholding\n",
    "            meas_fa[meas_fa < 200] = np.nan\n",
    "            meas_fa[meas_fa > 500] = np.nan\n",
    "        \n",
    "            # Fetch the flip angle from the JSON sidecar \n",
    "            with open(f\"{subject}_acq-famp-{voltage}_TB1DREAM.json\", \"r\") as f:\n",
    "                metadata = json.load(f)\n",
    "                requested_fa = metadata.get(\"FlipAngle\", \"N/A\")\n",
    "                #convert measured FA to percent of requested FA (note that measured FA map is in degrees * 10)\n",
    "                meas_fa = (meas_fa/10) / requested_fa\n",
    "        else:\n",
    "            meas_fa = np.full((nii.header).get_data_shape(),np.nan)\n",
    "\n",
    "        # Account for the power loss between the coil and the socket. That number was given by Siemens.\n",
    "        voltage_at_socket = ref_voltage * 10 ** -0.095\n",
    "        # Compute B1 map in [T/V]\n",
    "        # Siemens maps are in units of flip angle * 10 (in degrees)\n",
    "        b1_map = meas_fa * (np.pi / (GAMMA * 1e-3 * voltage_at_socket))\n",
    "        # Convert to [nT/V]\n",
    "        b1_map = b1_map * 1e9\n",
    "        \n",
    "        b1_maps.append(b1_map)\n",
    " \n",
    "    # compute mean of non-zero values\n",
    "    avgB1=np.nanmean(b1_maps,axis=0)\n",
    "    \n",
    "    # Save as NIfTI file\n",
    "    nii_avgB1 = nib.Nifti1Image(avgB1, nii.affine, nii.header)\n",
    "    nib.save(nii_avgB1, f\"{subject}_DREAMTB1avgB1map.nii.gz\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the TFL flip angle maps to B1+ efficiency maps [nT/V] (inspired by code from Kyle Gilbert)\n",
    "# The approach consists in calculating the B1+ efficiency using a 1ms, pi-pulse at the acquisition voltage,\n",
    "# then scale the efficiency by the ratio of the measured flip angle to the requested flip angle in the pulse sequence.\n",
    "\n",
    "GAMMA = 2.675e8;  # [rad / (s T)]\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "\n",
    "    if subject=='sub-MSSM1':\n",
    "        ref_voltage=450\n",
    "    elif subject=='sub-MSSM2':\n",
    "        ref_voltage=350\n",
    "    elif subject=='sub-MSSM3':\n",
    "        ref_voltage=450\n",
    "    else:     \n",
    "        # Fetch the reference voltage from the JSON sidecar \n",
    "        with open(f\"{subject}_acq-famp_TB1TFL.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "            ref_voltage = metadata.get(\"TxRefAmp\", \"N/A\")\n",
    "            if (ref_voltage == \"N/A\"):\n",
    "                ref_token = \"N/A\"\n",
    "                for token in metadata.get(\"SeriesDescription\", \"N/A\").split(\"_\"):\n",
    "                    if token.startswith(\"RefV\"): ref_token = token\n",
    "                ref_voltage = float(ref_token[4:-1])\n",
    "        \n",
    "    print(f\"ref_voltage [V]: {ref_voltage} ({subject}_acq-famp_TB1TFL)\")\n",
    "                \n",
    "    # Fetch the flip angle from the JSON sidecar \n",
    "    with open(f\"{subject}_acq-famp_TB1TFL.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        requested_fa = metadata.get(\"FlipAngle\", \"N/A\")\n",
    "        print(f\"flip angle [degrees]: {requested_fa} ({subject}_acq-famp_TB1TFL)\")\n",
    "\n",
    "    # Open flip angle map with nibabel\n",
    "    nii = nib.load(f\"{subject}_acq-famp_TB1TFL.nii.gz\")\n",
    "    meas_fa = nii.get_fdata()\n",
    "\n",
    "    # Account for the power loss between the coil and the socket. That number was given by Siemens.\n",
    "    voltage_at_socket = ref_voltage * 10 ** -0.095\n",
    "\n",
    "    # Compute B1 map in [T/V]\n",
    "    # Siemens maps are in units of flip angle * 10 (in degrees)\n",
    "    b1_map = ((meas_fa / 10) / requested_fa) * (np.pi / (GAMMA * 1e-3 * voltage_at_socket))\n",
    "\n",
    "    # Convert to [nT/V]\n",
    "    b1_map = b1_map * 1e9\n",
    "\n",
    "    # Save B1 map in [T/V] as NIfTI file\n",
    "    nii_b1 = nib.Nifti1Image(b1_map, nii.affine, nii.header)\n",
    "    nib.save(nii_b1, f\"{subject}_TFLTB1map.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Extract B1+ and SNR along the spinal cord "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Extract B1+ and SNR along the spinal cord between levels C1 and T2 (included) and save data to CSV files\n",
    "# TODO: remove code duplication\n",
    "\n",
    "for subject in subjects:\n",
    "    os.chdir(os.path.join(path_data, subject, \"fmap\"))\n",
    "    \n",
    "    # Extract TFL B1+ along the spinal cord\n",
    "    fname_result_b1plus = os.path.join(path_results, f\"{subject}_TFLTB1map.csv\")\n",
    "    !sct_extract_metric -i {subject}_TFLTB1map.nii.gz -f {subject}_acq-anat_TB1TFL_seg.nii.gz -method wa -vert 1:9 -vertfile {subject}_acq-anat_TB1TFL_seg_labeled-UNIT1reg.nii.gz -perlevel 1 -o \"{fname_result_b1plus}\"\n",
    "            \n",
    "    # Extract DREAM B1+ along the spinal cord\n",
    "    fname_result_b1plus = os.path.join(path_results, f\"{subject}_DREAMTB1avgB1map.csv\")\n",
    "    !sct_extract_metric -i {subject}_DREAMTB1avgB1map.nii.gz -f {subject}_acq-famp_TB1DREAM_seg.nii.gz -method wa -vert 1:9 -vertfile {subject}_acq-famp_TB1DREAM_seg_labeled-UNIT1reg.nii.gz -perlevel 1 -o \"{fname_result_b1plus}\"\n",
    "    \n",
    "    # Extract SNR along the spinal cord\n",
    "    fname_result_SNR = os.path.join(path_results, f\"{subject}_SNRmap.csv\")\n",
    "    !sct_extract_metric -i {subject}_acq-coilQaSagLarge_SNR_T0000.nii.gz -f {subject}_acq-coilQaSagLarge_SNR_T0000_seg.nii.gz -method wa -vert 1:9 -vertfile {subject}_acq-coilQaSagLarge_SNR_T0000_seg_labeled-UNIT1reg.nii.gz -perlevel 1 -o \"{fname_result_SNR}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Generate plots along spinal cord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df33d5",
   "metadata": {},
   "source": [
    "### Load and post-process extracted metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder subjects so that identical coils are displayed side-by-side\n",
    "subjects = ['sub-CRMBM1', 'sub-CRMBM2', 'sub-CRMBM3', 'sub-UCL1', 'sub-UCL2', 'sub-UCL3', 'sub-MNI1', 'sub-MNI2', 'sub-MNI3', 'sub-MGH1', 'sub-MGH2', 'sub-MGH3', 'sub-MPI1', 'sub-MPI2', 'sub-MPI3', 'sub-NTNU1', 'sub-NTNU2', 'sub-NTNU3', 'sub-MSSM1', 'sub-MSSM2', 'sub-MSSM3']\n",
    "\n",
    "# Go back to root data folder\n",
    "os.chdir(os.path.join(path_data))\n",
    "\n",
    "def smooth_data(data, window_size=20):\n",
    "    \"\"\" Apply a simple moving average to smooth the data. \"\"\"\n",
    "    return uniform_filter1d(data, size=window_size, mode='nearest')\n",
    "\n",
    "# Fixed grid for x-axis\n",
    "x_grid = np.linspace(0, 1, 100)\n",
    "\n",
    "# z-slices corresponding to levels C3 to T2 on the PAM50 template. These will be used to scale the x-label of each subject.\n",
    "original_vector = np.array([985, 939, 907, 870, 833, 800, 769, 735, 692, 646])\n",
    "\n",
    "# Normalize the PAM50 z-slice numbers to the 1-0 range (to show inferior-superior instead of superior-inferior)\n",
    "min_val = original_vector.min()\n",
    "max_val = original_vector.max()\n",
    "normalized_vector = 1 - ((original_vector - min_val) / (max_val - min_val))\n",
    "\n",
    "# Use this normalized vector as x-ticks\n",
    "custom_xticks = normalized_vector\n",
    "\n",
    "# Vertebral level labels\n",
    "vertebral_levels = [\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \"C7\", \"T1\", \"T2\"]\n",
    "# Calculate midpoints for label positions\n",
    "label_positions = normalized_vector[:-1] + np.diff(normalized_vector) / 2\n",
    "\n",
    "sites = [\"CRMBM\", \"UCL\", \"MNI\", \"MGH\", \"MPI\", \"NTNU\", \"MSSM\"]\n",
    "\n",
    "# map types\n",
    "map_types = [\"TFLTB1\", \"DREAMTB1avgB1\", \"SNR\"]\n",
    "\n",
    "# Data storage for statistics\n",
    "TFLTB1_data_stats = []\n",
    "DREAMTB1avgB1_data_stats = []\n",
    "SNR_TB1_data_stats = []\n",
    "\n",
    "data_stats = [TFLTB1_data_stats, DREAMTB1avgB1_data_stats, SNR_TB1_data_stats]\n",
    "\n",
    "# Data storage \n",
    "TFLTB1_data = {}\n",
    "DREAMTB1avgB1_data = {}\n",
    "SNR_data = {}\n",
    "data = [TFLTB1_data, DREAMTB1avgB1_data, SNR_data]\n",
    "\n",
    "\n",
    "for map_type, data_stats_type, data_type in zip(map_types,data_stats,data):\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    for site in sites:\n",
    "\n",
    "        data_type[site]={}\n",
    "\n",
    "\n",
    "        while i < (j+3):\n",
    "\n",
    "            os.chdir(os.path.join(path_data, f\"{subjects[i]}\", \"fmap\"))\n",
    "\n",
    "            # Initialize list to collect data for this subject\n",
    "            subject_data = []\n",
    "\n",
    "            file_csv = os.path.join(path_results, f\"{subjects[i]}_{map_type}map.csv\")\n",
    "            df = pd.read_csv(file_csv)\n",
    "            wa_data = df['WA()']\n",
    "\n",
    "            # Compute stats on the non-resampled data (to avoid interpolation errors)\n",
    "            mean_data = np.mean(wa_data)\n",
    "            sd_data = np.std(wa_data)\n",
    "\n",
    "            # Normalize the x-axis to a 1-0 scale for each subject (to go from superior-inferior direction)\n",
    "            x_subject = np.linspace(1, 0, len(wa_data))\n",
    "\n",
    "            # Interpolate to the fixed grid\n",
    "            interp_func = interp1d(x_subject, wa_data, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
    "            resampled_data = interp_func(x_grid)\n",
    "\n",
    "            # Apply smoothing\n",
    "            smoothed_data = smooth_data(resampled_data)\n",
    "            subject_data.append(smoothed_data)\n",
    "\n",
    "            for resampled_data in subject_data:\n",
    "                data_type[site][subjects[i]]=resampled_data\n",
    "                \n",
    "            data_stats_type.append([site, subjects[i], mean_data, sd_data])\n",
    "\n",
    "            i += 1        \n",
    "        j += 3       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Normalize slice average SNR values by slice-average TFL B1+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following https://onlinelibrary.wiley.com/doi/full/10.1002/mrm.27695; here we normalize SNR maps by sin(FA), where FA is the actual FA map for the GRE SNR scan\n",
    "# By normalizing we extrapolate to the SNR value that we would achive with FA = 90, ie, SNR_90 = SNR_meas/sin(FA_meas), which can be directly compated between RF coils\n",
    "\n",
    "# Since we do not have the FA_meas (for the SNR GRE scan), we will compute it from the ratio of the measured and requested FA in the TFL B1+ scan\n",
    "# FA_gre_meas = FA_gre_requested * (FA_TFL_meas/FA_TFL_requested)\n",
    "# FA_TFL_meas/FA_TFL_requested was previously computed to obtain the TFL B1+ efficiency (stored in \"data\"), we will reconvert TFL B1+ efficiency to the FA_TFL_meas/FA_TFL_requested ratio\n",
    "\n",
    "sites = [\"CRMBM\", \"UCL\", \"MNI\", \"MGH\", \"MPI\", \"NTNU\", \"MSSM\"]\n",
    "\n",
    "# SNR along the cord is stored in a dictionary (data) of dictionaries (?) that has an array associated with each element\n",
    "# The order of the dictionary is {'CRMBM': {'sub-CRMBM1': array([...]), 'sub-CRMBM2': array([...]), etc.\n",
    "# The 1st dictionary corresponds to the TFL B1+ data\n",
    "# The 3rd/last dictionary corresponds to the SNR data\n",
    "\n",
    "TFLB1_data = data[0]\n",
    "SNR_data = data[2]\n",
    "\n",
    "GAMMA = 2.675e8;  # [rad / (s T)]\n",
    "\n",
    "j = 0\n",
    "i = 0   \n",
    "for site in sites:   \n",
    "    while i < (j+3):\n",
    "\n",
    "        os.chdir(os.path.join(path_data, f\"{subjects[i]}\", \"fmap\"))\n",
    "\n",
    "        if subjects[i]=='sub-MSSM1':\n",
    "            ref_voltage=450\n",
    "        elif subjects[i]=='sub-MSSM2':\n",
    "            ref_voltage=350\n",
    "        elif subjects[i]=='sub-MSSM3':\n",
    "            ref_voltage=450\n",
    "        else:     \n",
    "            # Fetch the reference voltage from the JSON sidecar \n",
    "            with open(f\"{subjects[i]}_acq-famp_TB1TFL.json\", \"r\") as f:\n",
    "                metadata = json.load(f)\n",
    "                ref_voltage = metadata.get(\"TxRefAmp\", \"N/A\")\n",
    "                if (ref_voltage == \"N/A\"):\n",
    "                    ref_token = \"N/A\"\n",
    "                    for token in metadata.get(\"SeriesDescription\", \"N/A\").split(\"_\"):\n",
    "                        if token.startswith(\"RefV\"): ref_token = token\n",
    "                    ref_voltage = float(ref_token[4:-1])\n",
    "\n",
    "        # Account for the power loss between the coil and the socket. That number was given by Siemens.\n",
    "        voltage_at_socket = ref_voltage * 10 ** -0.095\n",
    "                \n",
    "        # Fetch the requested flip angle for the SNR(GRE) scan from the JSON sidecar \n",
    "        with open(f\"{subjects[i]}_acq-coilQaSagLarge_SNR.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "            requested_fa = metadata.get(\"FlipAngle\", \"N/A\")\n",
    "\n",
    "        # compute the actual flip angle for the SNR(GRE) scan \n",
    "        actual_fa = requested_fa * (TFLB1_data[site][subjects[i]]/1e9) * ((GAMMA * 1e-3 * voltage_at_socket)/np.pi)\n",
    "        # normalize the SNR data by the actual flip angle\n",
    "        data[2][site][subjects[i]] = SNR_data[site][subjects[i]]/np.sin(np.deg2rad(actual_fa))\n",
    "\n",
    "        i += 1       \n",
    "    j += 3\n",
    "\n",
    "    \n",
    "# replace SNR SC average and std in data_stats with SNR90 data\n",
    "j = 0\n",
    "i = 0\n",
    "k = 0\n",
    "for site in sites:   \n",
    "    while i < (j+3):\n",
    "\n",
    "        data_stats[2][k][2] = np.mean(data[2][site][subjects[i]])\n",
    "        data_stats[2][k][3] = np.std(data[2][site][subjects[i]])\n",
    "\n",
    "        k += 1\n",
    "\n",
    "        i += 1       \n",
    "    j += 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Generate plots of B1+ and SNR along the cord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = [\"CRMBM\", \"UCL\", \"MNI\", \"MGH\", \"MPI\", \"NTNU\", \"MSSM\"]\n",
    "site_colors = ['cornflowerblue', 'royalblue', 'firebrick', 'darkred', 'limegreen', 'green', 'mediumpurple']\n",
    "\n",
    "subject_names = [\"Subject 1\", \"Subject 2\", \"Subject 3\", \"average\"]\n",
    "sub_linestyles = ['dotted','dashed','dashdot']\n",
    "sub_colors = ['dimgray','darkgray','silver']\n",
    "\n",
    "# figure types\n",
    "fig_types = [\"TFL B1+ [nT/V]\", \"DREAM B1+ [nT/V]\", \"SNR_90\"]\n",
    "    \n",
    "for data_type, data_stats_type, fig_type in zip(data, data_stats, fig_types):\n",
    "    \n",
    "    avg_data = {'CRMBM': 0, 'UCL': 0, 'MNI': 0, 'MGH': 0, 'MPI': 0, 'NTNU': 0, 'MSSM': 0}\n",
    "   \n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(1, len(sites), wspace=0)\n",
    "    axs = gs.subplots(sharex=True, sharey=True)\n",
    "    fig.set_size_inches(16, 6)\n",
    "\n",
    "    j = 0\n",
    "    i = 0    \n",
    "    for k, site in enumerate(sites):    \n",
    "        l = 0\n",
    "        while i < (j+3):\n",
    "            axs[k].plot(data_type[site][subjects[i]],color=sub_colors[l], linestyle=sub_linestyles[l])\n",
    "            avg_data[site] += data_type[site][subjects[i]]\n",
    "            l += 1\n",
    "            i += 1\n",
    "        j += 3\n",
    "        \n",
    "        avg_data[site] = avg_data[site]/3\n",
    "        \n",
    "        axs[k].plot(avg_data[site],color=\"black\",linestyle='solid',linewidth=1)\n",
    "        axs[k].set_title(sites[k], color=site_colors[k])\n",
    "        axs[k].grid()\n",
    "    \n",
    "    axs[0].legend(subject_names,loc=\"upper right\")\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Vertebral Levels', ylabel=fig_type, xticks=100*label_positions, xticklabels=vertebral_levels)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='center')\n",
    "\n",
    "    if fig_type==\"SNR_90\":\n",
    "        ax.set_ylim(200, 1300)\n",
    "    else:\n",
    "        ax.set_ylim(0, 85)  \n",
    "        \n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    print('Subject-averaged', fig_type,'averaged along SC:',*zip(*{k: np.mean(v) for k, v in avg_data.items()}.items()),'\\n')\n",
    "    print('Subject-averaged', fig_type,'std along SC:',*zip(*{k: np.std(v) for k, v in avg_data.items()}.items()),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe65256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some stats\n",
    "# to do: automate this \n",
    "\n",
    "print(\"CRMBM std across subjects of mean TFL B1+ along SC: \",np.std([data_stats[0][0][2],data_stats[0][1][2],data_stats[0][2][2]]))\n",
    "print(\"UCL std across subjects of mean TFL B1+ along SC: \",np.std([data_stats[0][3][2],data_stats[0][4][2],data_stats[0][5][2]]))\n",
    "print(\"MNI std across subjects of mean TFL B1+ along SC: \",np.std([data_stats[0][6][2],data_stats[0][7][2],data_stats[0][8][2]]))\n",
    "print(\"MGH std across subjects of mean TFL B1+ along SC: \",np.std([data_stats[0][9][2],data_stats[0][10][2],data_stats[0][11][2]]))\n",
    "print(\"MPI std across subjects of mean TFL B1+ along SC: \",np.std([data_stats[0][12][2],data_stats[0][13][2],data_stats[0][14][2]]))\n",
    "print(\"NTNU std across subjects of mean TFL B1+ along SC: \",np.std([data_stats[0][15][2],data_stats[0][16][2],data_stats[0][17][2]]))\n",
    "print(\"MSSM std across subjects of mean TFL B1+ along SC: \",np.std([data_stats[0][18][2],data_stats[0][19][2],data_stats[0][20][2]]))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"CRMBM std across subjects of mean DREAM B1+ along SC: \",np.std([data_stats[1][0][2],data_stats[1][1][2],data_stats[1][2][2]]))\n",
    "print(\"UCL std across subjects of mean DREAM B1+ along SC: \",np.std([data_stats[1][3][2],data_stats[1][4][2],data_stats[1][5][2]]))\n",
    "print(\"MNI std across subjects of mean DREAM B1+ along SC: \",np.std([data_stats[1][6][2],data_stats[1][7][2],data_stats[1][8][2]]))\n",
    "print(\"MGH std across subjects of mean DREAM B1+ along SC: \",np.std([data_stats[1][9][2],data_stats[1][10][2],data_stats[1][11][2]]))\n",
    "print(\"MPI std across subjects of mean DREAM B1+ along SC: \",np.std([data_stats[1][12][2],data_stats[1][13][2],data_stats[1][14][2]]))\n",
    "print(\"NTNU std across subjects of mean DREAM B1+ along SC: \",np.std([data_stats[1][15][2],data_stats[1][16][2],data_stats[1][17][2]]))\n",
    "print(\"MSSM std across subjects of mean DREAM B1+ along SC: \",np.std([data_stats[1][18][2],data_stats[1][19][2],data_stats[1][20][2]]))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"CRMBM std across subjects: \",np.mean([np.std([data_stats[0][0][2],data_stats[0][1][2],data_stats[0][2][2]]),np.std([data_stats[1][0][2],data_stats[1][1][2],data_stats[1][2][2]])]))\n",
    "print(\"UCL std across subjects: \",np.mean([np.std([data_stats[0][3][2],data_stats[0][4][2],data_stats[0][5][2]]),np.std([data_stats[1][3][2],data_stats[1][4][2],data_stats[1][5][2]])]))\n",
    "print(\"MNI std across subjects: \",np.mean([np.std([data_stats[0][6][2],data_stats[0][7][2],data_stats[0][8][2]]),np.std([data_stats[1][6][2],data_stats[1][7][2],data_stats[1][8][2]])]))\n",
    "print(\"MGH std across subjects: \",np.mean([np.std([data_stats[0][9][2],data_stats[0][10][2],data_stats[0][11][2]]),np.std([data_stats[1][9][2],data_stats[1][10][2],data_stats[1][11][2]])]))\n",
    "print(\"MPI std across subjects: \",np.mean([np.std([data_stats[0][12][2],data_stats[0][13][2],data_stats[0][14][2]]),np.std([data_stats[1][12][2],data_stats[1][13][2],data_stats[1][14][2]])]))\n",
    "print(\"NTNU std across subjects: \",np.mean([np.std([data_stats[0][15][2],data_stats[0][16][2],data_stats[0][17][2]]),np.std([data_stats[1][15][2],data_stats[1][16][2],data_stats[1][17][2]])]))\n",
    "print(\"MSSM std across subjects: \",np.mean([np.std([data_stats[0][18][2],data_stats[0][19][2],data_stats[0][20][2]]),np.std([data_stats[1][18][2],data_stats[1][19][2],data_stats[1][20][2]])]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Generate plots of B1+ and SNR per vertebral levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure types\n",
    "site_colors = ['cornflowerblue', 'royalblue', 'firebrick', 'darkred', 'limegreen', 'green', 'mediumpurple']\n",
    "fig_types = [\"TFL B1+ CoV [nT/V] across C1-T2\", \"DREAM B1+ CoV [nT/V] across C1-T2\", \"SNR_90 Mean [arb] across C1-T2\"]\n",
    "subject_names = [\"Subject 1\", \"Subject 2\", \"Subject 3\"]\n",
    "sub_colors = ['dimgray','darkgray','silver']\n",
    "\n",
    "for data_stats_type, fig_type in zip(data_stats,fig_types):\n",
    "    \n",
    "    series = [data_stats_type[i::len(subject_names)] for i in range(len(subject_names))]\n",
    "    hline_x = np.arange(len(sites))\n",
    "    hline_width = 0.25\n",
    "    stat_metric = np.zeros((len(subject_names),len(sites)))\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    i = 0\n",
    "    for subject_name, subject_series in zip(subject_names, series): \n",
    "        if fig_type == \"SNR_90 Mean [arb] across C1-T2\":\n",
    "            # Compute mean across levels\n",
    "            metric_indiv = [subject_series[j][2] for j in range(len(sites))]\n",
    "        else:\n",
    "            # Compute CoV across levels\n",
    "            metric_indiv = [subject_series[j][3]/subject_series[j][2] for j in range(len(sites))]\n",
    "        ax.scatter(sites, metric_indiv, label=subject_name, color=sub_colors[i])\n",
    "        for xtick, site_color in zip(ax.get_xticklabels(), site_colors):\n",
    "            xtick.set_color(site_color)        \n",
    "        for j in range(len(sites)):\n",
    "            if fig_type == \"SNR_90 Mean [arb] across C1-T2\":\n",
    "                # Compute mean across levels and subjects\n",
    "                stat_metric[i][j] = subject_series[j][2]\n",
    "            else:\n",
    "                # Compute CoV across levels and subjects\n",
    "                stat_metric[i][j] = subject_series[j][3]/subject_series[j][2]\n",
    "        i+=1\n",
    "    \n",
    "    plt.hlines(np.mean(stat_metric, axis=0),hline_x - hline_width/2, hline_x + hline_width/2, color=\"black\", label=\"Across subj. mean\")\n",
    "        \n",
    "    ax.legend()\n",
    "    if fig_type==\"SNR_90 Mean [arb] across C1-T2\":\n",
    "        ax.set_ylim(200, 1000)\n",
    "        #ax.get_legend().remove()\n",
    "    else:\n",
    "        ax.set_ylim(0, 0.5)     \n",
    "    ax.set_title(fig_type)\n",
    "\n",
    "    plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Generate maps\n",
    "\n",
    "Generate figures for B1+, SNR, and 1/g-factor maps obtained at each site (for one representative subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf10efe",
   "metadata": {},
   "source": [
    "### Co-register maps to reference site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Co-register subjects across sites for better visualisation\n",
    "\n",
    "sites = [\"CRMBM\", \"UCL\", \"MNI\", \"MGH\", \"MPI\", \"NTNU\", \"MSSM\"]\n",
    "subject_id = '3'  # Subject number to generate figures from\n",
    "site_ref = 'CRMBM'\n",
    "vert_labels = '3'  # vertebral levels for alignment between sites\n",
    "\n",
    "files_anat = [\"acq-anat_TB1TFL\", \"acq-famp_TB1DREAM\",\"acq-coilQaSagLarge_SNR_T0000\"]  # image that serves as a reference to get the segmentation\n",
    "files_metric = [\"TFLTB1map\", \"DREAMTB1avgB1map\",\"acq-coilQaSagLarge_SNR_T0000\"]  # coilQA image to display on the figure\n",
    "\n",
    "for site in sites:\n",
    "    print(f\"👉 PROCESSING: {site}{subject_id}\")\n",
    "    for file_anat, file_metric in zip(files_anat, files_metric):\n",
    "        os.chdir(os.path.join(path_data, \"sub-\"+site+subject_id, \"fmap\"))\n",
    "        # Extract vertebral labels\n",
    "        !sct_label_utils -i sub-{site}{subject_id}_{file_anat}_seg_labeled-UNIT1reg.nii.gz -vert-body {vert_labels} -o sub-{site}{subject_id}_{file_anat}_labels.nii.gz\n",
    "        # Co-register data to reference subject\n",
    "        if site != \"CRMBM\":\n",
    "            !sct_register_multimodal \\\n",
    "                -i sub-{site}{subject_id}_{file_metric}.nii.gz \\\n",
    "                -iseg sub-{site}{subject_id}_{file_anat}_seg.nii.gz \\\n",
    "                -ilabel sub-{site}{subject_id}_{file_anat}_labels.nii.gz \\\n",
    "                -d ../../sub-{site_ref}{subject_id}/fmap/sub-{site_ref}{subject_id}_{file_metric}.nii.gz \\\n",
    "                -dseg ../../sub-{site_ref}{subject_id}/fmap/sub-{site_ref}{subject_id}_{file_anat}_seg.nii.gz \\\n",
    "                -dlabel ../../sub-{site_ref}{subject_id}/fmap/sub-{site_ref}{subject_id}_{file_anat}_labels.nii.gz \\\n",
    "                -param step=0,type=label,dof=Tx_Ty_Tz:step=1,type=seg,iter=0 \\\n",
    "                -x nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb9cc32",
   "metadata": {},
   "source": [
    "### Align spinal cord with the medial plane\n",
    "\n",
    "For visualization purpose, such that the sagittal views show the spinal cord throughout the whole superior-inferior axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the spinal cord (ie, being it into the sagittal midline)\n",
    "\n",
    "for site in sites:\n",
    "    print(f\"👉 PROCESSING: {site}{subject_id}\")\n",
    "    for file_anat, file_metric in zip(files_anat, files_metric):\n",
    "        os.chdir(os.path.join(path_data, \"sub-\"+site+subject_id, \"fmap\"))\n",
    "        if site == site_ref:\n",
    "            suffix = \"\"\n",
    "        else:\n",
    "            suffix = \"_reg\"\n",
    "        # Flatten the spinal cord in the sagittal plane\n",
    "        !sct_flatten_sagittal -i sub-{site}{subject_id}_{file_metric}{suffix}.nii.gz -s ../../sub-{site_ref}{subject_id}/fmap/sub-{site_ref}{subject_id}_{file_anat}_seg.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e3d8f",
   "metadata": {},
   "source": [
    "### Generate B1+ and SNR maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_colors = ['cornflowerblue', 'royalblue', 'firebrick', 'darkred', 'limegreen', 'green', 'mediumpurple']\n",
    "\n",
    "# legend types\n",
    "legend_types = [\"[nT/V]\", \"[nT/V]\", \"[arb]\", \"[arb]\", \"[arb]\"]\n",
    "\n",
    "# Define the slicing indices for each combination of file_metric and ind_subject\n",
    "# The indices are defined as (x(min, max), y(min, max))\n",
    "slicing_indices = {\n",
    "    \"TFLTB1map\": {\n",
    "        '1': (slice(31, 82), slice(43, 93)),\n",
    "        '2': (slice(28, 71), slice(37, 94)),\n",
    "        '3': (slice(25, 77), slice(35, 100))\n",
    "    },\n",
    "    \"DREAMTB1avgB1map\": {\n",
    "        '1': (slice(29, 60), slice(13, 66)),\n",
    "        '2': (slice(20, 65), slice(6, 56)),\n",
    "        '3': (slice(25, 72), slice(0, 60))\n",
    "    },\n",
    "    \"acq-coilQaSagLarge_SNR_T0000\": {\n",
    "        '1': (slice(224, 302), slice(213, 292)),\n",
    "        '2': (slice(224, 302), slice(197, 289)),\n",
    "        '3': (slice(100, 178), slice(55, 160))\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the dynmax values for each file_metric\n",
    "dynmax_values = {\n",
    "    \"TFLTB1map\": 60,\n",
    "    \"DREAMTB1avgB1map\": 60,\n",
    "    \"acq-coilQaSagLarge_SNR_T0000\": 200\n",
    "}\n",
    "\n",
    "for file_metric, legend_type in zip(files_metric, legend_types):\n",
    "    # Create a figure with multiple subplots\n",
    "    fig, axes = plt.subplots(2, 4)#, figsize=(10, 8))\n",
    "    font_size = 12\n",
    "    axes=axes.flatten() \n",
    "    for i,site in enumerate(sites):\n",
    "        # Load data\n",
    "        os.chdir(os.path.join(path_data, f\"sub-{site}{subject_id}\", \"fmap\"))\n",
    "        if site == site_ref:\n",
    "            suffix = \"\"\n",
    "        else:\n",
    "            suffix = \"_reg\"\n",
    "        map = nib.load(f\"sub-{site}{subject_id}_{file_metric}{suffix}_flatten.nii.gz\")\n",
    "        # map = nib.load(f\"sub-{site}{ind_subject}_{file_metric}{suffix}.nii.gz\")\n",
    "        slices = slicing_indices[file_metric][subject_id]\n",
    "        data = map.get_fdata()[slices[0], slices[1], round(map.get_fdata().shape[2] / 2)]\n",
    "\n",
    "        # Figure configuration\n",
    "        axes[-1].axis('off') \n",
    "        # Defining dynamic range\n",
    "        axes[-1].axis('off')            \n",
    "        dynmin = 0 \n",
    "        dynmax = dynmax_values[file_metric]\n",
    "        splot=axes[i]\n",
    "        im = splot.imshow((data.T), cmap='viridis', origin='lower',vmin=dynmin,vmax=dynmax)\n",
    "        splot.set_title(site, size=font_size,color=site_colors[i])\n",
    "        splot.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Colorbar\n",
    "    # Assume that the colorbar should start at the bottom of the lower row of subplots and\n",
    "    # extend to the top of the upper row of subplots\n",
    "    cbar_bottom = 0.25  # This might need adjustment\n",
    "    cbar_height = 0.5  # This represents the total height of both rows of subplots\n",
    "    cbar_dist = 1.01\n",
    "    cbar_ax = fig.add_axes([cbar_dist, cbar_bottom, 0.03, cbar_height])\n",
    "    cbar = plt.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "    cbar_ax.set_title(legend_type, size=12)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98acd431",
   "metadata": {},
   "source": [
    "### Generate g-factor maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map types\n",
    "map_types = [\"acq-coilQaSagSmall_GFactor\", \"acq-coilQaTra_GFactor\", \"T2starw\"]\n",
    "\n",
    "sites = [\"CRMBM\", \"MNI\", \"MPI\", \"MSSM\", \"UCL\", \"MGH\", \"NTNU\"]\n",
    "site_colors = ['cornflowerblue', 'firebrick', 'limegreen', 'mediumpurple', 'royalblue', 'darkred', 'green']\n",
    "\n",
    "# legend types\n",
    "legend_types = [\"1/g\", \"1/g\", \"[arb]\"]\n",
    "\n",
    "# Select individual subject to show\n",
    "ind_subject = '2'  # Here we select subject 2 because it has the most complete data\n",
    "\n",
    "mean_gfac = {}\n",
    "max_gfac = {}\n",
    "\n",
    "for map_type, legend_type in zip(map_types,legend_types):\n",
    "    \n",
    "    # Create a figure with multiple subplots\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(10, 8))\n",
    "    font_size = 12\n",
    "    axes=axes.flatten() \n",
    "\n",
    "    for i,site in enumerate(sites):\n",
    "        # Load data\n",
    "        if map_type==\"T2starw\":\n",
    "            os.chdir(os.path.join(path_data, f\"sub-{site}{ind_subject}\", \"anat\"))\n",
    "            map=nib.load(f\"sub-{site}{ind_subject}_{map_type}.nii.gz\")\n",
    "            data=map.get_fdata()[:,:,round(map.get_fdata().shape[2]/2)]\n",
    "        else:\n",
    "            os.chdir(os.path.join(path_data, f\"sub-{site}{ind_subject}\", \"fmap\"))\n",
    "            map=nib.load(f\"sub-{site}{ind_subject}_{map_type}.nii.gz\")\n",
    "            # The 4th dimension inlcudes 12 acceleration maps: \n",
    "            #['R 2','R 3', 'R 4', 'R 6', 'R 8', 'R 2 x 2', 'R 2 x 3', 'R 3 x 2', 'R 3 x 3', 'R 3 x 4', 'R 4 x 3', 'R 4 x 4']\n",
    "            if map_type==\"acq-coilQaSagSmall_GFactor\":   \n",
    "                # show the R = 2 x 2 map\n",
    "                data=(map.get_fdata()[64:191,64:191,round(map.get_fdata().shape[2]/2),0])/1000\n",
    "                gfac_data=(map.get_fdata()[round(map.get_fdata().shape[0]/2)-10:round(map.get_fdata().shape[0]/2)+10,round(map.get_fdata().shape[1]/2)-10:round(map.get_fdata().shape[1]/2)+10,round(map.get_fdata().shape[2]/2),5])\n",
    "            else:\n",
    "                # show the R = 2 map\n",
    "                data=(map.get_fdata()[192:574,192:574,round(map.get_fdata().shape[2]/2),0])/1000\n",
    "                gfac_data=(map.get_fdata()[round(map.get_fdata().shape[0]/2)-30:round(map.get_fdata().shape[0]/2)+30,round(map.get_fdata().shape[1]/2)-30:round(map.get_fdata().shape[1]/2)+30,round(map.get_fdata().shape[2]/2),0])\n",
    "            \n",
    "            mean_gfac[site]=np.nanmean(gfac_data)/1000\n",
    "            max_gfac[site]=np.max(gfac_data)/1000\n",
    "\n",
    "        # Plot  \n",
    "        splot=axes[i]\n",
    "        dynmin = 0 \n",
    "        if map_type==\"T2starw\":\n",
    "            dynmax = 3000\n",
    "            axes[-1].axis('off')\n",
    "        else:\n",
    "            dynmax = 1\n",
    "            axes[-1].axis('off')\n",
    "            splot.text(0, 3, r'mean 1/g='+str(round(mean_gfac[site],4)), size=10)\n",
    "            \n",
    "            if map_type==\"acq-coilQaSagSmall_GFactor\":\n",
    "                x = [data.shape[0]/2-10, data.shape[1]/2-10] \n",
    "                y = [data.shape[0]/2-10, data.shape[1]/2+10] \n",
    "                splot.plot(x, y, color=\"black\", linewidth=2) \n",
    "                \n",
    "                x = [data.shape[0]/2-10, data.shape[1]/2+10] \n",
    "                y = [data.shape[0]/2+10, data.shape[1]/2+10] \n",
    "                splot.plot(x, y, color=\"black\", linewidth=2) \n",
    "    \n",
    "                x = [data.shape[0]/2+10, data.shape[1]/2+10] \n",
    "                y = [data.shape[0]/2+10, data.shape[1]/2-10] \n",
    "                splot.plot(x, y, color=\"black\", linewidth=2)\n",
    "    \n",
    "                x = [data.shape[0]/2+10, data.shape[1]/2-10] \n",
    "                y = [data.shape[0]/2-10, data.shape[1]/2-10] \n",
    "                splot.plot(x, y, color=\"black\", linewidth=2)  \n",
    "            else:\n",
    "                x = [data.shape[0]/2-30, data.shape[1]/2-30] \n",
    "                y = [data.shape[0]/2-30, data.shape[1]/2+30] \n",
    "                splot.plot(x, y, color=\"black\", linewidth=2) \n",
    "                \n",
    "                x = [data.shape[0]/2-30, data.shape[1]/2+30] \n",
    "                y = [data.shape[0]/2+30, data.shape[1]/2+30] \n",
    "                splot.plot(x, y, color=\"black\", linewidth=2) \n",
    "    \n",
    "                x = [data.shape[0]/2+30, data.shape[1]/2+30] \n",
    "                y = [data.shape[0]/2+30, data.shape[1]/2-30] \n",
    "                splot.plot(x, y, color=\"black\", linewidth=2)\n",
    "    \n",
    "                x = [data.shape[0]/2+30, data.shape[1]/2-30] \n",
    "                y = [data.shape[0]/2-30, data.shape[1]/2-30] \n",
    "                splot.plot(x, y, color=\"black\", linewidth=2) \n",
    "            \n",
    "        im = splot.imshow((data.T), cmap='viridis', origin='lower',vmin=dynmin,vmax=dynmax)  \n",
    "        splot.set_title(site, size=font_size,color=site_colors[i])\n",
    "        splot.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Colorbar\n",
    "    # Assume that the colorbar should start at the bottom of the lower row of subplots and\n",
    "    # extend to the top of the upper row of subplots\n",
    "    cbar_bottom = 0.25  # This might need adjustment\n",
    "    cbar_height = 0.5  # This represents the total height of both rows of subplots\n",
    "    cbar_dist = 1.01\n",
    "    cbar_ax = fig.add_axes([cbar_dist, cbar_bottom, 0.03, cbar_height])\n",
    "    cbar = plt.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "    cbar_ax.set_title(legend_type, size=12)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## Generate tiled figure with individual channel on GRE scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = [\"CRMBM\", \"UCL\", \"MNI\", \"MGH\", \"MPI\", \"NTNU\", \"MSSM\"]\n",
    "\n",
    "# Select subject to show\n",
    "subject = '1'  # and here we select subject 1 because it has the most complete data\n",
    "\n",
    "        \n",
    "for i,site in enumerate(sites):\n",
    "\n",
    "    gre_files=sorted(glob.glob(os.path.join(path_data, f\"sub-{site}{subject}\", \"anat\", '*uncombined*.nii.gz')))\n",
    "        \n",
    "    #Tiled figure in a five-row layout\n",
    "    rows=int(np.ceil(len(gre_files)/4))\n",
    "    cols=int(np.ceil(len(gre_files)/rows))\n",
    "\n",
    "    fig=plt.figure(figsize=(15, 20))\n",
    "    \n",
    "    ax = fig.subplots(rows,cols,squeeze=True)\n",
    "    \n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "\n",
    "            i = row*cols+col\n",
    "\n",
    "            if i < len(gre_files):\n",
    "            \n",
    "                #read in files\n",
    "                data_to_plot=(nib.load(gre_files[i])).get_fdata() #load in nifti object, get only image data\n",
    "                data_to_plot=np.rot90(data_to_plot[:,:,int(np.floor(data_to_plot.shape[2]/2))]) #central slice\n",
    "           \n",
    "                ax[row,col].imshow(data_to_plot,cmap=plt.cm.gray,clim=[0, 300])\n",
    "                ax[row,col].text(0.5, 0.05, 'Rx channel : ' + str(i+1),horizontalalignment='center', transform=ax[row,col].transAxes,color='white',fontsize=17)\n",
    "                ax[row,col].axis('off')\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(hspace=0,wspace=0)\n",
    "    fig.suptitle(site, fontsize=20, y=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## Finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate duration of data processing\n",
    "\n",
    "end_time = datetime.now()\n",
    "total_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Convert seconds to a timedelta object\n",
    "total_time_delta = timedelta(seconds=total_time)\n",
    "\n",
    "# Format the timedelta object to a string\n",
    "formatted_time = str(total_time_delta)\n",
    "\n",
    "# Pad the string representation if less than an hour\n",
    "formatted_time = formatted_time.rjust(8, '0')\n",
    "\n",
    "print(f\"Total Runtime [hour:min:sec]: {formatted_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
